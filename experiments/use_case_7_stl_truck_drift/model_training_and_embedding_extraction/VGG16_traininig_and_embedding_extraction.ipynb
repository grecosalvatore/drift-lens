{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7e6151a0-8f3c-4f11-ab13-07eca648b69c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "so far so good...\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_curve, auc, roc_auc_score\n",
    "import numpy as np\n",
    "\n",
    "# Load images from a pickle file\n",
    "with open(\"stl_test.pickle\", \"rb\") as tr_images_file:\n",
    "    test = pickle.load(tr_images_file)\n",
    "with open(\"stl_train.pickle\", \"rb\") as tr_images_file:\n",
    "    train = pickle.load(tr_images_file)\n",
    "with open(\"stl_val.pickle\", \"rb\") as tr_images_file:\n",
    "    new = pickle.load(tr_images_file)\n",
    "with open(\"stl_deg.pickle\", \"rb\") as tr_images_file:\n",
    "    deg = pickle.load(tr_images_file)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "80c6cb7a-1651-4c53-bd6e-2f065625e905",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eccezioni\n",
      "0\n",
      "eccezioni\n",
      "0\n",
      "eccezioni\n",
      "0\n",
      "eccezioni\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def unpk(data):\n",
    "\n",
    "    x=[]\n",
    "    y=[]\n",
    "    c=0\n",
    "    tot=[]\n",
    "    for pair in data:\n",
    "        try:\n",
    "            img=np.array(pair[0]).reshape((96,96,3))\n",
    "            x.append(img)\n",
    "            y.append(pair[1])\n",
    "        except Exception as e:\n",
    "            c=c+1\n",
    "    \n",
    "    print(\"exceptions\")\n",
    "    print(c)\n",
    "    return x, y\n",
    "\n",
    "x_train,y_trai=unpk(train)\n",
    "x_test,y_tes=unpk(test)\n",
    "x_new, y_ne=unpk(new)\n",
    "x_deg, y_deg=unpk(deg)\n",
    "c2=0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "066f6b8d-a091-42ef-8471-bb67e157269f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "y_deg=[]\n",
    "y_train=[]\n",
    "y_test=[]\n",
    "y_new=[]\n",
    "\n",
    "#this part is to reasses the labels so that label 9 is drift\n",
    "for i in range(len(x_deg)):\n",
    "    y_deg.append(9)\n",
    "\n",
    "for i in range(len(y_trai)):\n",
    "    if y_trai[i]==9:\n",
    "        y_train.append(3)\n",
    "    else:\n",
    "        y_train.append(y_trai[i])\n",
    "\n",
    "for i in range(len(y_tes)):\n",
    "    if y_tes[i]==9:\n",
    "        y_test.append(3)\n",
    "    else:\n",
    "        y_test.append(y_tes[i])\n",
    "\n",
    "for i in range(len(y_ne)):\n",
    "    if y_ne[i]==9:\n",
    "        y_new.append(3)\n",
    "    else:\n",
    "        y_new.append(y_ne[i])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5dab89f2-1989-49c2-bb3a-64720fe0c209",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_train_x=x_train.copy()\n",
    "new_train_y=y_train.copy()\n",
    "\n",
    "new_x_test=[]\n",
    "new_y_test=[]\n",
    "\n",
    "for i in range(len(x_test)):\n",
    "        new_x_test.append(x_test[i])\n",
    "        new_y_test.append(y_test[i])\n",
    "    \n",
    "\n",
    "new_train_x=np.array(new_train_x)\n",
    "new_test_x=np.array(new_x_test)\n",
    "new_train_y=np.array(new_train_y)\n",
    "new_test_y=np.array(new_y_test)\n",
    "x_new=np.array(x_new)\n",
    "x_deg=np.array(x_deg)\n",
    "y_new=np.array(y_new)\n",
    "y_deg=np.array(y_deg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "505e9908-901d-4a3e-84d9-54ce6eb11256",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5850\n",
      "2925\n",
      "2925\n",
      "1300\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "print(len(new_train_x))\n",
    "print(len(new_test_x))\n",
    "print(len(x_new))\n",
    "print(len(x_deg))\n",
    "print(type(new_train_x))\n",
    "print(type(new_train_x))\n",
    "print(type(x_new))\n",
    "print(type(x_deg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "84a261f5-28d0-439f-8e79-9d85b9f1b47f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-24 15:17:43.524895: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-11-24 15:17:43.560251: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2023-11-24 15:17:43.560287: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2023-11-24 15:17:43.561984: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-11-24 15:17:43.568865: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-11-24 15:17:43.569561: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-11-24 15:17:44.376618: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "[1. 0. 0. 0. 0. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "print(new_train_y[0])\n",
    "\n",
    "cat_lab_train=to_categorical(new_train_y)\n",
    "cat_lab_test=to_categorical(new_test_y)\n",
    "cat_lab_new=to_categorical(y_new)\n",
    "cat_lab_deg=to_categorical(y_deg)\n",
    "\n",
    "print(cat_lab_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f1214573-29b2-4512-84cd-82ce3ecd736e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "117/117 [==============================] - 23s 191ms/step - loss: 10.2187 - acc: 0.6347\n",
      "Epoch 2/10\n",
      "117/117 [==============================] - 21s 180ms/step - loss: 0.5732 - acc: 0.8103\n",
      "Epoch 3/10\n",
      "117/117 [==============================] - 21s 180ms/step - loss: 0.3982 - acc: 0.8607\n",
      "Epoch 4/10\n",
      "117/117 [==============================] - 21s 180ms/step - loss: 0.2673 - acc: 0.9039\n",
      "Epoch 5/10\n",
      "117/117 [==============================] - 21s 181ms/step - loss: 0.2024 - acc: 0.9270\n",
      "Epoch 6/10\n",
      "117/117 [==============================] - 21s 183ms/step - loss: 0.1597 - acc: 0.9443\n",
      "Epoch 7/10\n",
      "117/117 [==============================] - 21s 183ms/step - loss: 0.1216 - acc: 0.9561\n",
      "Epoch 8/10\n",
      "117/117 [==============================] - 21s 182ms/step - loss: 0.1057 - acc: 0.9617\n",
      "Epoch 9/10\n",
      "117/117 [==============================] - 21s 182ms/step - loss: 0.0865 - acc: 0.9694\n",
      "Epoch 10/10\n",
      "117/117 [==============================] - 21s 181ms/step - loss: 0.0618 - acc: 0.9762\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.applications.vgg16 import VGG16\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.layers import Flatten, Dense\n",
    "\n",
    "\n",
    "base_model=VGG16(weights='imagenet', include_top=False, input_shape=(96,96,3))\n",
    "\n",
    "\n",
    "for layer in base_model.layers[:]:\n",
    "        layer.trainable = False\n",
    "        \n",
    "model=Sequential()\n",
    "model.add(base_model)\n",
    "model.add(Flatten(name=\"fl\"))\n",
    "model.add(Dense(256, activation=\"relu\", name=\"fc\"))\n",
    "model.add(Dense(9, activation=\"softmax\"))\n",
    "\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=\"sgd\", metrics=[\"acc\"])\n",
    "\n",
    "model.fit(new_train_x, cat_lab_train, batch_size=50, epochs=10, validation_split=0)\n",
    "\n",
    "\n",
    "#model_e= Model(inputs=model.input, outputs=model.get_layer('fc').output)\n",
    "model_e=base_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bd407bb6-afe2-45f1-8b9f-225ecd7208ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92/92 [==============================] - 12s 125ms/step\n",
      "[[223   0  43  13  15   2  25   0   4]\n",
      " [  1 303   0   1   2  10   1   4   3]\n",
      " [ 35   0 215  19  14   0  22   0  20]\n",
      " [ 14   0   9 269  10   1  11   0  11]\n",
      " [ 13   0   7   5 277   3  20   0   0]\n",
      " [  1   6   0   2   6 289   0  18   3]\n",
      " [ 19   0  20   6  16   0 258   0   6]\n",
      " [  1   3   0   0   0  21   0 297   3]\n",
      " [  7   0  17  37   4   3   9   4 244]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.69      0.70       325\n",
      "           1       0.97      0.93      0.95       325\n",
      "           2       0.69      0.66      0.68       325\n",
      "           3       0.76      0.83      0.79       325\n",
      "           4       0.81      0.85      0.83       325\n",
      "           5       0.88      0.89      0.88       325\n",
      "           6       0.75      0.79      0.77       325\n",
      "           7       0.92      0.91      0.92       325\n",
      "           8       0.83      0.75      0.79       325\n",
      "\n",
      "    accuracy                           0.81      2925\n",
      "   macro avg       0.81      0.81      0.81      2925\n",
      "weighted avg       0.81      0.81      0.81      2925\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix, roc_curve, auc, roc_auc_score\n",
    "\n",
    "\n",
    "pred=model.predict(new_test_x)\n",
    "\n",
    "print(confusion_matrix(new_test_y, pred.argmax(1)))\n",
    "\n",
    "# Print classification report\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(new_test_y, pred.argmax(1)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "84917618-42ac-483d-a82d-198300cec308",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def embedding_creation(X, y):\n",
    "    predictions=model.predict(X)\n",
    "    #conv_embedding=base_model.predict(X)\n",
    "    embedding=model_e.predict(X)\n",
    "\n",
    "    emb_list=[]\n",
    "    \n",
    "    prediction_list=[]\n",
    "\n",
    "    for i in range(len(X)):\n",
    "        emb_list.append(embedding[i])\n",
    "        #conv_emb_list.append(conv_embedding[i])\n",
    "        prediction_list.append(predictions[i])\n",
    "\n",
    "    emb_list=np.array(emb_list)\n",
    "    #conv_emb_list=np.array(conv_emb_list)\n",
    "\n",
    "    prediction_list=np.array(prediction_list)\n",
    "    prediction_list=np.argmax(prediction_list, axis=1)\n",
    "    \n",
    "\n",
    "    return prediction_list, emb_list,  y\n",
    "    \n",
    "def save_embeddings(embedding, predicted_label, true_label, path):\n",
    "    fp = h5py.File(path, \"w\")\n",
    "    fp.create_dataset(\"E\", data=embedding, compression=\"gzip\")\n",
    "    fp.create_dataset(\"Y_predicted\", data=predicted_label, compression=\"gzip\") \n",
    "    fp.create_dataset(\"Y_original\", data=true_label, compression=\"gzip\") \n",
    "    fp.close()\n",
    "    print(\"embeddings saved\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ebc7ce4c-ce41-4c1b-a19f-f11edddb3d22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training embedding extraction...\n",
      "183/183 [==============================] - 23s 127ms/step\n",
      "183/183 [==============================] - 23s 126ms/step\n",
      "test embedding creation...\n",
      "92/92 [==============================] - 12s 127ms/step\n",
      "92/92 [==============================] - 12s 128ms/step\n",
      "new embedding creation...\n",
      "92/92 [==============================] - 11s 122ms/step\n",
      "92/92 [==============================] - 12s 126ms/step\n",
      "degerated data embedding creation...\n",
      "41/41 [==============================] - 5s 123ms/step\n",
      "41/41 [==============================] - 5s 125ms/step\n",
      "saving the embeddings...\n",
      "embeddings saved\n",
      "embeddings saved\n",
      "embeddings saved\n",
      "embeddings saved\n"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "\n",
    "\n",
    "print(\"training embedding extraction...\")\n",
    "prediction_training, embedding_training, true_label_trainining=embedding_creation(new_train_x, new_train_y)\n",
    "print(\"test embedding creation...\")\n",
    "prediction_test, embedding_test,  true_label_test=embedding_creation(new_test_x, new_test_y)\n",
    "print(\"new embedding creation...\")\n",
    "prediction_new, embedding_new, true_label_new=embedding_creation(x_new, y_new)\n",
    "print(\"drifted data embedding creation...\")\n",
    "#el=False\n",
    "prediction_deg, embedding_deg, true_label_deg=embedding_creation(x_deg, y_deg)\n",
    "\n",
    "print(\"saving the embeddings...\")\n",
    "\n",
    "save_embeddings(embedding_training, prediction_training, true_label_trainining, \"Conv_VGG-16_Stl_train.hdf5\" )\n",
    "save_embeddings(embedding_test, prediction_test, true_label_test, \"Conv_VGG-16_Stl_test.hdf5\" )\n",
    "save_embeddings(embedding_new, prediction_new, true_label_new, \"Conv_VGG-16_Stl_new.hdf5\" )\n",
    "save_embeddings(embedding_deg, prediction_deg, true_label_deg, \"Conv_VGG-16_Stl_deg.hdf5\" )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1a3148d-5a1c-4450-a05f-1c561bf5b096",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}