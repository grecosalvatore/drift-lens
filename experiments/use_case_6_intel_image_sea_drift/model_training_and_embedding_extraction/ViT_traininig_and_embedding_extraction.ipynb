{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7d4bc84e-921d-46b6-b225-91febb6a45c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_curve, auc, roc_auc_score\n",
    "import numpy as np\n",
    "\n",
    "# Load images from a pickle file\n",
    "with open(\"II_test.pickle\", \"rb\") as tr_images_file:\n",
    "    test = pickle.load(tr_images_file)\n",
    "with open(\"II_train.pickle\", \"rb\") as tr_images_file:\n",
    "    train = pickle.load(tr_images_file)\n",
    "with open(\"II_val.pickle\", \"rb\") as tr_images_file:\n",
    "    new = pickle.load(tr_images_file)\n",
    "with open(\"II_deg.pickle\", \"rb\") as tr_images_file:\n",
    "    deg = pickle.load(tr_images_file)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c784a045-8b22-4452-92b6-2efe8b3472cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "exceptions\n",
      "16\n",
      "exceptions\n",
      "19\n",
      "exceptions\n",
      "19\n",
      "exceptions\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def unpk(data):\n",
    "\n",
    "    x=[]\n",
    "    y=[]\n",
    "    c=0\n",
    "    tot=[]\n",
    "    for image, labels in data:\n",
    "        try:\n",
    "            img=np.array(image).reshape((150,150,3))\n",
    "            x.append(img)\n",
    "            y.append(labels)\n",
    "        except Exception as e:\n",
    "            c=c+1\n",
    "    \n",
    "    print(\"exceptions\")\n",
    "    print(c)\n",
    "    return x, y\n",
    "\n",
    "x_train,y_train=unpk(train)\n",
    "x_test,y_test=unpk(test)\n",
    "x_new, y_new=unpk(new)\n",
    "x_deg, y_deg=unpk(deg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1e76e47f-a3b7-4703-a311-4713814c8080",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6000\n",
      "4000\n"
     ]
    }
   ],
   "source": [
    "new_train_x=x_train.copy()\n",
    "new_train_y=y_train.copy()\n",
    "\n",
    "new_x_test=[]\n",
    "new_y_test=[]\n",
    "\n",
    "for i in range(len(x_test)):\n",
    "    if i <4000:\n",
    "        new_x_test.append(x_test[i])\n",
    "        new_y_test.append(y_test[i])\n",
    "    else:\n",
    "        new_train_x.append(x_test[i])\n",
    "        new_train_y.append(y_test[i])\n",
    "#we add this to have clean division 60-40% of the dataset        \n",
    "for i in range(60):\n",
    "    new_train_x.append(new_train_x[i])\n",
    "    new_train_y.append(new_train_y[i])\n",
    "print(len(new_train_x))\n",
    "print(len(new_x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cb936887-08ff-416c-8673-2069d0d5b976",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_into_format(data, labels):\n",
    "    formatted_data=[]\n",
    "    for i in range(len(data)):\n",
    "        formatted_data.append((data[i], labels[i]))\n",
    "\n",
    "    \n",
    "    return formatted_data\n",
    "\n",
    "\n",
    "train_ds=data_into_format(new_train_x, new_train_y)\n",
    "test_ds=data_into_format(new_x_test, new_y_test)\n",
    "new_ds=data_into_format(x_new, y_new)\n",
    "deg_ds=data_into_format(x_deg, y_deg)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "abb77f0d-9ea4-4ce8-9e9c-304a0985558c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import ViTModel\n",
    "from transformers.modeling_outputs import SequenceClassifierOutput\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class ViTForImageClassification(nn.Module):\n",
    "    def __init__(self, num_labels=5):\n",
    "        super(ViTForImageClassification, self).__init__()\n",
    "        self.vit = ViTModel.from_pretrained('google/vit-base-patch16-224-in21k')\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "        self.classifier = nn.Linear(self.vit.config.hidden_size, num_labels)\n",
    "        self.num_labels = num_labels\n",
    "\n",
    "    def forward(self, pixel_values, labels):\n",
    "        outputs = self.vit(pixel_values=pixel_values)\n",
    "        output = self.dropout(outputs.last_hidden_state[:,0])\n",
    "        logits = self.classifier(output)\n",
    "\n",
    "        loss = None\n",
    "        if labels is not None:\n",
    "          loss_fct = nn.CrossEntropyLoss()\n",
    "          loss = loss_fct(logits.view(-1, self.num_labels), labels.view(-1))\n",
    "        if loss is not None:\n",
    "          return logits, loss.item()\n",
    "        else:\n",
    "          return logits, None\n",
    "    \n",
    "    def emb_extr(self, pixel_values):\n",
    "        \n",
    "        self.embedding_layer = nn.Identity()\n",
    "        x = self.patch_embeddings(pixel_values)\n",
    "        \n",
    "        for block in self.blocks[:-1]:  # Exclude the last block\n",
    "            x = block(x)\n",
    "\n",
    "        # Capture the output of the last transformer block\n",
    "        embeddings = self.embedding_layer(x)\n",
    "\n",
    "        # Apply Global Average Pooling\n",
    "        embeddings = embeddings.mean(dim=(1, 2))\n",
    "\n",
    "        # Forward pass through the classification head\n",
    "        x = self.head(embeddings)\n",
    "\n",
    "        #return x, embeddings\n",
    "        return embeddings\n",
    "    \n",
    "    def emb_extr_new_v1(self, pixel_values):\n",
    "        \n",
    "        outputs = self.vit(pixel_values=pixel_values)\n",
    "        #output = self.dropout(outputs.last_hidden_state[:,0])\n",
    "        #for layer in model.children():\n",
    "        \n",
    "        return outputs.last_hidden_state[:,0]\n",
    "    \n",
    "    def emb_extr_new_v2(self, pixel_values):\n",
    "        \n",
    "        outputs = self.vit(pixel_values=pixel_values)\n",
    "        #output = self.dropout(outputs.last_hidden_state[:,0])\n",
    "        #for layer in model.children():\n",
    "        \n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "170c17fc-ce61-49da-8b47-23817ce7e7ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 5\n",
    "BATCH_SIZE = 100\n",
    "LEARNING_RATE = 2e-5\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7d5a9e77-06d0-42d3-8bae-529424709b63",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import ViTFeatureExtractor\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "# Define Model\n",
    "model = ViTForImageClassification(5)    \n",
    "# Feature Extractor\n",
    "feature_extractor = ViTFeatureExtractor.from_pretrained('google/vit-base-patch16-224-in21k')\n",
    "# Adam Optimizer\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "# Cross Entropy Loss\n",
    "loss_func = nn.CrossEntropyLoss()\n",
    "# Use GPU if available  \n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu') \n",
    "if torch.cuda.is_available():\n",
    "    model.cuda() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "235f6e01-2400-4929-8c6c-43913efb4137",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training...\n",
      "Epoch:  0 | train loss: 1.4145 | test accuracy: 0.71\n"
     ]
    }
   ],
   "source": [
    "import torch.utils.data as data\n",
    "from torch.autograd import Variable\n",
    "import numpy as np\n",
    "\n",
    "#print(\"Number of train samples: \", len(train_ds))\n",
    "#print(\"Number of test samples: \", len(test_ds))\n",
    "#print(\"Detected Classes are: \", train_ds.class_to_idx) \n",
    "\n",
    "train_loader = data.DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True,  num_workers=4)\n",
    "test_loader  = data.DataLoader(test_ds, batch_size=BATCH_SIZE, shuffle=True, num_workers=4) \n",
    "print(\"training...\")\n",
    "# Train the model\n",
    "for epoch in range(EPOCHS):        \n",
    "    for step, (x, y) in enumerate(train_loader):\n",
    "        # Change input array into list with each batch being one element\n",
    "        x = np.split(np.squeeze(np.array(x)), BATCH_SIZE)\n",
    "        # Remove unecessary dimension\n",
    "        for index, array in enumerate(x):\n",
    "            x[index] = np.squeeze(array)\n",
    "        # Apply feature extractor, stack back into 1 tensor and then convert to tensor\n",
    "        x = torch.tensor(np.stack(feature_extractor(x)['pixel_values'], axis=0))\n",
    "        # Send to GPU if available\n",
    "        x, y  = x.to(device), y.to(device)\n",
    "        b_x = Variable(x)   # batch x (image)\n",
    "        b_y = Variable(y)   # batch y (target)\n",
    "        # Feed through model\n",
    "        output, loss = model(b_x, None)\n",
    "        # Calculate loss\n",
    "        if loss is None: \n",
    "            loss = loss_func(output, b_y)   \n",
    "            optimizer.zero_grad()           \n",
    "            loss.backward()                 \n",
    "            optimizer.step()\n",
    "\n",
    "        if step % 50 == 0:\n",
    "            # Get the next batch for testing purposes\n",
    "            test = next(iter(test_loader))\n",
    "            test_x = test[0]\n",
    "            # Reshape and get feature matrices as needed\n",
    "            test_x = np.split(np.squeeze(np.array(test_x)), BATCH_SIZE)\n",
    "            for index, array in enumerate(test_x):\n",
    "                test_x[index] = np.squeeze(array)\n",
    "            test_x = torch.tensor(np.stack(feature_extractor(test_x)['pixel_values'], axis=0))\n",
    "            # Send to appropirate computing device\n",
    "            test_x = test_x.to(device)\n",
    "            test_y = test[1].to(device)\n",
    "            # Get output (+ respective class) and compare to target\n",
    "            test_output, loss = model(test_x, test_y)\n",
    "            test_output = test_output.argmax(1)\n",
    "            # Calculate Accuracy\n",
    "            accuracy = (test_output == test_y).sum().item() / BATCH_SIZE\n",
    "            print('Epoch: ', epoch, '| train loss: %.4f' % loss, '| test accuracy: %.2f' % accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed4dd705-c8c4-41b2-9854-264f7621d76b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "\n",
    "num_classes = 5  # Replace with the number of classes in your specific task\n",
    "\n",
    "model.eval()\n",
    "\n",
    "class CustomTestDataset():\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        image, label = self.data[index]\n",
    "        # Perform any necessary preprocessing on the image\n",
    "        transform = transforms.Compose([\n",
    "            transforms.Resize((224, 224)),\n",
    "            transforms.ToTensor(),\n",
    "        ])\n",
    "        image = transform(Image.fromarray(image))\n",
    "        return image, label\n",
    "\n",
    "# Create a DataLoader for the test dataset\n",
    "test_dataset = CustomTestDataset(test_ds)\n",
    "test_dataloader = data.DataLoader(test_dataset, batch_size=50, shuffle=False)\n",
    "\n",
    "# Perform inference on the test set\n",
    "all_labels = []\n",
    "all_predictions = []\n",
    "\n",
    "print(\"evaluation...\")\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in test_dataloader:\n",
    "        outputs, loss = model(inputs, labels)\n",
    "        _, predictions = torch.max(outputs, 1)\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "        all_predictions.extend(predictions.cpu().numpy())\n",
    "        #all_embeddings.append(embeddings.cpu().numpy())\n",
    "\n",
    "# Evaluate the model\n",
    "\n",
    "print(confusion_matrix(all_labels, all_predictions))\n",
    "\n",
    "# Print classification report\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(all_labels, all_predictions))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "438d54a6-3ddc-4670-9718-62d7a3ebb42e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train\n",
      "inizio extraction embedding...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2138420/645840759.py:14: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.\n",
      "  embeddings=np.array(embeddings)\n",
      "/tmp/ipykernel_2138420/645840759.py:14: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  embeddings=np.array(embeddings)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test\n",
      "inizio extraction embedding...\n",
      "new\n",
      "inizio extraction embedding...\n",
      "deg\n",
      "inizio extraction embedding...\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "def embedding_extraction(modello, dataloader):\n",
    "    \n",
    "    embeddings=[]\n",
    "    print(\"extraction embedding...\")\n",
    "\n",
    "    with torch.no_grad():\n",
    "        embeddings = []\n",
    "\n",
    "        for images, _ in dataloader:  # Adjust this loop based on your data loading\n",
    "            outputs = modello.emb_extr_new_v1(images)\n",
    "            #emb_extr_new_v1\n",
    "            embeddings.append(outputs)\n",
    "            \n",
    "    embeddings=np.array(embeddings)\n",
    "            \n",
    "    return embeddings\n",
    "\n",
    "def into_dataloader(ds):\n",
    "    dataset = CustomTestDataset(ds)\n",
    "    dataloader = data.DataLoader(dataset, batch_size=50, shuffle=False)\n",
    "    \n",
    "    return dataloader\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "model.eval()\n",
    "# Perform inference on the test set\n",
    "\n",
    "\n",
    "print(\"train\")\n",
    "train_emb=embedding_extraction(model, into_dataloader(train_ds))\n",
    "print(\"test\")\n",
    "test_emb=embedding_extraction(model, into_dataloader(test_ds))\n",
    "print(\"new\")\n",
    "new_emb=embedding_extraction(model, into_dataloader(new_ds))\n",
    "print(\"drift\")\n",
    "deg_emb=embedding_extraction(model, into_dataloader(deg_ds))\n",
    "\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "179f85bc-19c2-4957-a732-968c477b0799",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predictions...\n",
      "train\n",
      "inizio evaluation...\n",
      "test\n",
      "inizio evaluation...\n",
      "new\n",
      "inizio evaluation...\n",
      "deg\n",
      "inizio evaluation...\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "def prediction_extraction(modello, dataloader):\n",
    "    all_labels = []\n",
    "    all_predictions = []\n",
    "\n",
    "    print(\"inizio evaluation...\")\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in dataloader:\n",
    "            outputs, loss = modello(inputs, labels=None)\n",
    "            _, predictions = torch.max(outputs, 1)\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "            all_predictions.extend(predictions.cpu().numpy())\n",
    "            #all_embeddings.append(embeddings.cpu().numpy())\n",
    "            \n",
    "    return all_predictions, all_labels\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\"predictions...\")\n",
    "print(\"train\")\n",
    "train_pred, train_lab=prediction_extraction(model, into_dataloader(train_ds))\n",
    "print(\"test\")\n",
    "test_pred, test_lab=prediction_extraction(model, into_dataloader(test_ds))\n",
    "print(\"new\")\n",
    "new_pred, new_lab=prediction_extraction(model, into_dataloader(new_ds))\n",
    "print(\"drift\")\n",
    "deg_pred, deg_lab=prediction_extraction(model, into_dataloader(deg_ds))\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0af204bb-39f9-4a14-9916-4d16816fffeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120\n",
      "6000\n",
      "50\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "print(len(train_emb))\n",
    "print(len(train_lab))\n",
    "\n",
    "print(len(train_emb[0]))\n",
    "print(train_lab[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e050ba09-5df3-41bb-b278-055d015ac216",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "debatching...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2138420/1921475119.py:7: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.\n",
      "  final_e=np.array(final_e, dtype='object')\n"
     ]
    }
   ],
   "source": [
    "def de_batch(emb):\n",
    "    final_e=[]\n",
    "    for i in range(len(emb)):\n",
    "        for j in range(len(emb[i])):\n",
    "            final_e.append(emb[i][j])\n",
    "    \n",
    "    final_e=np.array(final_e, dtype='object')\n",
    "    return final_e\n",
    "\n",
    "print(\"debatching...\")\n",
    "\n",
    "final_train_emb=de_batch(train_emb)\n",
    "final_test_emb=de_batch(test_emb)\n",
    "final_new_emb=de_batch(new_emb)\n",
    "final_deg_emb=de_batch(deg_emb)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9f843a05-3c06-4ff6-9def-c09647d95bbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train...\n",
      "0\n",
      "500\n",
      "1000\n",
      "1500\n",
      "2000\n",
      "2500\n",
      "3000\n",
      "3500\n",
      "4000\n",
      "4500\n",
      "5000\n",
      "5500\n",
      "test...\n",
      "0\n",
      "500\n",
      "1000\n",
      "1500\n",
      "2000\n",
      "2500\n",
      "3000\n",
      "3500\n",
      "new...\n",
      "0\n",
      "500\n",
      "1000\n",
      "1500\n",
      "2000\n",
      "2500\n",
      "3000\n",
      "3500\n",
      "4000\n",
      "deg...\n",
      "0\n",
      "500\n",
      "1000\n",
      "1500\n",
      "2000\n",
      "2500\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def final_step(dati):\n",
    "    temp=[]\n",
    "    for i in range(len(dati)):\n",
    "        if i%500==0:\n",
    "            print(i)\n",
    "        tmp=[]\n",
    "        for j in range(len(dati[i])):\n",
    "            tmp.append(dati[i][j])\n",
    "        temp.append(np.array(tmp))\n",
    "    \n",
    "    temp=np.array(temp)\n",
    "    \n",
    "    return temp\n",
    "\n",
    "print(\"train...\")\n",
    "fin_train_emb=final_step(final_train_emb)\n",
    "print(\"test...\")\n",
    "fin_test_emb=final_step(final_test_emb)\n",
    "print(\"new...\")\n",
    "fin_new_emb=final_step(final_new_emb)\n",
    "print(\"deg...\")\n",
    "fin_deg_emb=final_step(final_deg_emb)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ef46edc1-7c29-49c5-9483-3aa75fb70419",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "embeddings saved\n",
      "embeddings saved\n",
      "embeddings saved\n",
      "embeddings saved\n"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "\n",
    "def save_embeddings(embedding, true_label,pr_label, path):\n",
    "    fp = h5py.File(path, \"w\")\n",
    "    fp.create_dataset(\"E\", data=embedding, compression=\"gzip\")    \n",
    "    fp.create_dataset(\"Y_predicted\", data=pr_label, compression=\"gzip\") \n",
    "    fp.create_dataset(\"Y_original\", data=true_label, compression=\"gzip\") \n",
    "    fp.close()\n",
    "    print(\"embeddings saved\")\n",
    "\n",
    "train_path=\"vit_Intel_train_emb.hdf5\"\n",
    "test_path=\"vit_Intel_test_emb.hdf5\"\n",
    "new_path=\"vit_Intel_new_emb.hdf5\"\n",
    "deg_path=\"vit_Intel_deg_emb.hdf5\"\n",
    "\n",
    "save_embeddings(fin_train_emb, train_lab, train_pred, train_path )\n",
    "save_embeddings(fin_test_emb, test_lab, test_pred, test_path )\n",
    "save_embeddings(fin_new_emb, new_lab, new_pred, new_path)\n",
    "save_embeddings(fin_deg_emb, deg_lab, deg_pred, deg_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}