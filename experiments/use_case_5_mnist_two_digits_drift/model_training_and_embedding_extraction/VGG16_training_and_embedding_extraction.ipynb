{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7d4bc84e-921d-46b6-b225-91febb6a45c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_curve, auc, roc_auc_score\n",
    "import numpy as np\n",
    "import csv\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "\n",
    "# Load the CSV file into a pandas DataFrame\n",
    "train_df = pd.read_csv('mnist_train.csv')\n",
    "test_df = pd.read_csv('mnist_test.csv')\n",
    "# Extract labels and features\n",
    "train_labels = train_df.iloc[:, 0]  # the label is in the first column\n",
    "train_features = train_df.iloc[:, 1:]  \n",
    "test_labels = test_df.iloc[:, 0]  # the label is in the first column\n",
    "test_features = test_df.iloc[:, 1:]  \n",
    "\n",
    "# Convert into numpy arrays\n",
    "train_labels_array = train_labels.to_numpy()\n",
    "train_features_array = train_features.to_numpy()\n",
    "test_labels_array = test_labels.to_numpy()\n",
    "test_features_array = test_features.to_numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b852ddf2-98b3-4bf4-811a-4e0ce3701ee6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000\n",
      "10000\n",
      "<class 'numpy.ndarray'>\n",
      "784\n"
     ]
    }
   ],
   "source": [
    "print(len(train_labels_array))\n",
    "print(len(test_labels_array))\n",
    "print(type(train_features_array))\n",
    "\n",
    "print(len(train_features_array[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "461ddc06-5dde-48aa-a6a0-62733a6a99c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "removing label 9 from train...\n",
      "removing label 9 from test...\n",
      "13783\n",
      "48200\n",
      "8017\n"
     ]
    }
   ],
   "source": [
    "deg_l1=9\n",
    "deg_l2=8\n",
    "deg_data=[]\n",
    "deg_labels=[]\n",
    "\n",
    "new_train_data=[]\n",
    "new_train_lab=[]\n",
    "print(\"removing label 8 9 from train...\")\n",
    "for i in range(len(train_labels_array)):\n",
    "    if train_labels_array[i]==deg_l1 or train_labels_array[i]==deg_l2:\n",
    "        deg_data.append(train_features_array[i])\n",
    "        deg_labels.append(train_labels_array[i])\n",
    "    else:\n",
    "        new_train_data.append(train_features_array[i])\n",
    "        new_train_lab.append(train_labels_array[i])\n",
    "        \n",
    "new_test_data=[]\n",
    "new_test_lab=[]\n",
    "print(\"removing label 8 9 from test...\")\n",
    "for i in range(len(test_labels_array)):\n",
    "    if test_labels_array[i]==deg_l1 or test_labels_array[i]==deg_l2:\n",
    "        deg_data.append(test_features_array[i])\n",
    "        deg_labels.append(test_labels_array[i])\n",
    "    else:\n",
    "        new_test_data.append(test_features_array[i])\n",
    "        new_test_lab.append(test_labels_array[i])\n",
    "        \n",
    "print(len(deg_data))\n",
    "print(len(new_train_data))\n",
    "print(len(new_test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3a4ce810-8928-4ad9-a243-fb78f102cf43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48200\n",
      "48200\n",
      "12532\n",
      "35668\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#separating new unseen data from training set\n",
    "\n",
    "rp=13/50\n",
    "print(len(new_train_data))\n",
    "print(len(new_train_lab))\n",
    "nn_tr_data,new_unseen_data, nn_tr_lab ,new_unseen_lab=train_test_split(new_train_data, new_train_lab, test_size=rp, stratify=new_train_lab, random_state=42)\n",
    "\n",
    "\n",
    "print(len(new_unseen_data))\n",
    "print(len(nn_tr_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7aaa8fd0-53b2-4521-b2d0-708350b34484",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35000\n",
      "35000\n",
      "8000\n",
      "12000\n",
      "13000\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "#rebalancing the different data sets\n",
    "\n",
    "final_train_data=[]\n",
    "final_train_lab=[]\n",
    "final_test_data=[]\n",
    "final_test_lab=[]\n",
    "final_unseen_data=[]\n",
    "final_unseen_lab=[]\n",
    "final_deg_data=[]\n",
    "final_deg_lab=[]\n",
    "deg_label=8\n",
    "c=0\n",
    "for i in range(35000):\n",
    "        final_train_data.append(nn_tr_data[i])\n",
    "        final_train_lab.append(nn_tr_lab[i])\n",
    "\n",
    "for i in range(12000):\n",
    "        final_unseen_data.append(new_unseen_data[i])\n",
    "        final_unseen_lab.append(new_unseen_lab[i])    \n",
    "        \n",
    "for i in range(8000):\n",
    "        final_test_data.append(new_test_data[i])\n",
    "        final_test_lab.append(new_test_lab[i]) \n",
    "\n",
    "c=50\n",
    "for i in range(13000):\n",
    "    try:\n",
    "        final_deg_data.append(deg_data[i])\n",
    "        final_deg_lab.append(deg_label)\n",
    "    except Exception as e:\n",
    "        #random_elements = np.random.choice(range(6000), size=1, replace=False)  # Set replace=True if you want to allow duplicates\n",
    "        final_deg_data.append(deg_data[i-c])\n",
    "        final_deg_lab.append(deg_label)\n",
    "        c=c+1\n",
    "\n",
    "print(len(final_train_lab))\n",
    "print(len(final_train_data))\n",
    "print(len(final_test_lab))\n",
    "print(len(final_unseen_lab))\n",
    "print(len(final_deg_lab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c784a045-8b22-4452-92b6-2efe8b3472cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(784,)\n",
      "exceptions\n",
      "0\n",
      "exceptions\n",
      "0\n",
      "exceptions\n",
      "0\n",
      "exceptions\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "def image_conv(imgs_array):\n",
    "\n",
    "    x=[]\n",
    "    c=0\n",
    "    tot=[]\n",
    "    for i in range(len(imgs_array)):\n",
    "        try:\n",
    "            rgb_image = np.stack((imgs_array[i],) * 3, axis=-1)\n",
    "            img=np.array(rgb_image).reshape((28,28,3))\n",
    "            \n",
    "            # Pad the array\n",
    "            padding = ((2, 2), (2, 2), (0, 0))\n",
    "            padded_array = np.pad(img, padding, mode='constant', constant_values=0)\n",
    "\n",
    "            \n",
    "            x.append(padded_array)\n",
    "            #img=np.array(ims_array[i]).reshape(28,28,1)\n",
    "            #x.append(img)\n",
    "            \n",
    "        except Exception as e:\n",
    "            c=c+1\n",
    "    \n",
    "    print(\"exceptions\")\n",
    "    print(c)\n",
    "    return x\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(final_train_data[0].shape)\n",
    "ult_train_data=image_conv(final_train_data)\n",
    "ult_test_data=image_conv(final_test_data)\n",
    "ult_unseen_data=image_conv(final_unseen_data)\n",
    "ult_deg_data=image_conv(final_deg_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "968dbb56-e515-405f-be69-06729b72812d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "x_train=np.array(ult_train_data)\n",
    "cat_lab_train=to_categorical(final_train_lab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ce20bbb9-cccd-4796-b9bd-f27d2e6267be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "700/700 [==============================] - 31s 43ms/step - loss: 1.0899 - acc: 0.8135\n",
      "Epoch 2/10\n",
      "700/700 [==============================] - 28s 40ms/step - loss: 0.2828 - acc: 0.9041\n",
      "Epoch 3/10\n",
      "700/700 [==============================] - 28s 40ms/step - loss: 0.2233 - acc: 0.9238\n",
      "Epoch 4/10\n",
      "700/700 [==============================] - 28s 40ms/step - loss: 0.2018 - acc: 0.9301\n",
      "Epoch 5/10\n",
      "700/700 [==============================] - 28s 40ms/step - loss: 0.1854 - acc: 0.9372\n",
      "Epoch 6/10\n",
      "700/700 [==============================] - 27s 39ms/step - loss: 0.1639 - acc: 0.9437\n",
      "Epoch 7/10\n",
      "700/700 [==============================] - 27s 38ms/step - loss: 0.1507 - acc: 0.9487\n",
      "Epoch 8/10\n",
      "700/700 [==============================] - 27s 38ms/step - loss: 0.1428 - acc: 0.9510\n",
      "Epoch 9/10\n",
      "700/700 [==============================] - 27s 39ms/step - loss: 0.1346 - acc: 0.9534\n",
      "Epoch 10/10\n",
      "700/700 [==============================] - 27s 39ms/step - loss: 0.1330 - acc: 0.9559\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.applications.vgg16 import VGG16\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.layers import Flatten, Dense\n",
    "\n",
    "#load pretrained model\n",
    "\n",
    "base_model=VGG16(weights='imagenet', include_top=False, input_shape=(32,32,3))\n",
    "\n",
    "\n",
    "for layer in base_model.layers[:]:\n",
    "        layer.trainable = False\n",
    "        \n",
    "model=Sequential()\n",
    "model.add(base_model)\n",
    "model.add(Flatten(name=\"fl\"))\n",
    "model.add(Dense(256, activation=\"relu\", name=\"fc\"))\n",
    "model.add(Dense(8, activation=\"softmax\"))\n",
    "\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=\"sgd\", metrics=[\"acc\"])\n",
    "\n",
    "model.fit(x_train, cat_lab_train, batch_size=50, epochs=10, validation_split=0)\n",
    "\n",
    "\n",
    "#this model has as output the output of the convolutional layers\n",
    "model_e=base_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9be01adc-ab8b-44ca-8df6-1de32245f7dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_test_x=np.array(ult_test_data)\n",
    "new_test_y=final_test_lab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5077264f-14f8-43ec-85c4-c8eaf0e116a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250/250 [==============================] - 7s 29ms/step\n",
      "[[ 953    0    4    0    2    2   17    0]\n",
      " [   0 1114    0    1    8    0    7    3]\n",
      " [   3    1  941   18    9   23   33    2]\n",
      " [   0    0   18  926    0   58    5    1]\n",
      " [   0    5    4    0  951    2   16    2]\n",
      " [   0    0   15   27    1  827   16    3]\n",
      " [   1    2    1    3    4    6  938    0]\n",
      " [   2    4   50    1   31    6    0  933]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.97      0.98       978\n",
      "           1       0.99      0.98      0.99      1133\n",
      "           2       0.91      0.91      0.91      1030\n",
      "           3       0.95      0.92      0.93      1008\n",
      "           4       0.95      0.97      0.96       980\n",
      "           5       0.90      0.93      0.91       889\n",
      "           6       0.91      0.98      0.94       955\n",
      "           7       0.99      0.91      0.95      1027\n",
      "\n",
      "    accuracy                           0.95      8000\n",
      "   macro avg       0.95      0.95      0.95      8000\n",
      "weighted avg       0.95      0.95      0.95      8000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix, roc_curve, auc, roc_auc_score\n",
    "\n",
    "\n",
    "pred=model.predict(new_test_x)\n",
    "\n",
    "print(confusion_matrix(new_test_y, pred.argmax(1)))\n",
    "\n",
    "# Print classification report\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(new_test_y, pred.argmax(1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "679d7153-807e-4e2c-83b5-5e440bd1b6d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def embedding_creation(X, y):\n",
    "    predictions=model.predict(X)\n",
    "    #conv_embedding=base_model.predict(X)\n",
    "    embedding=model_e.predict(X)\n",
    "\n",
    "    emb_list=[]\n",
    "    \n",
    "    prediction_list=[]\n",
    "\n",
    "    for i in range(len(X)):\n",
    "        emb_list.append(embedding[i])\n",
    "        #conv_emb_list.append(conv_embedding[i])\n",
    "        prediction_list.append(predictions[i])\n",
    "\n",
    "    emb_list=np.array(emb_list)\n",
    "    #conv_emb_list=np.array(conv_emb_list)\n",
    "\n",
    "    prediction_list=np.array(prediction_list)\n",
    "    prediction_list=np.argmax(prediction_list, axis=1)\n",
    "    \n",
    "\n",
    "    return prediction_list, emb_list,  y\n",
    "    \n",
    "def save_embeddings(embedding, predicted_label, true_label, path):\n",
    "    fp = h5py.File(path, \"w\")\n",
    "    fp.create_dataset(\"E\", data=embedding, compression=\"gzip\")\n",
    "    fp.create_dataset(\"Y_predicted\", data=predicted_label, compression=\"gzip\") \n",
    "    fp.create_dataset(\"Y_original\", data=true_label, compression=\"gzip\") \n",
    "    fp.close()\n",
    "    print(\"embeddings saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1e46bc56-63d8-4094-a360-47a715d8760b",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_train_x=x_train\n",
    "new_train_y=final_train_lab\n",
    "new_test_x=np.array(ult_test_data)\n",
    "new_test_y=final_test_lab\n",
    "x_new=np.array(ult_unseen_data)\n",
    "y_new=final_unseen_lab\n",
    "x_deg=np.array(ult_deg_data)\n",
    "y_deg=final_deg_lab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d01b5fcf-021b-462b-a61d-83f812d56834",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training embedding extraction...\n",
      "1094/1094 [==============================] - 31s 29ms/step\n",
      "1094/1094 [==============================] - 31s 28ms/step\n",
      "test embedding creation...\n",
      "250/250 [==============================] - 7s 29ms/step\n",
      "250/250 [==============================] - 7s 29ms/step\n",
      "new embedding creation...\n",
      "375/375 [==============================] - 11s 29ms/step\n",
      "375/375 [==============================] - 11s 28ms/step\n",
      "degerated data embedding creation...\n",
      "407/407 [==============================] - 12s 29ms/step\n",
      "407/407 [==============================] - 12s 28ms/step\n",
      "saving the embeddings...\n",
      "embeddings saved\n",
      "embeddings saved\n",
      "embeddings saved\n",
      "embeddings saved\n"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "\n",
    "# here we strore the predictions of the model, the embeddings extracted from the convolutional layers and the original label\n",
    "\n",
    "print(\"training embedding extraction...\")\n",
    "prediction_training, embedding_training, true_label_trainining=embedding_creation(new_train_x, new_train_y)\n",
    "print(\"test embedding creation...\")\n",
    "prediction_test, embedding_test,  true_label_test=embedding_creation(new_test_x, new_test_y)\n",
    "print(\"new embedding creation...\")\n",
    "prediction_new, embedding_new, true_label_new=embedding_creation(x_new, y_new)\n",
    "print(\"degerated data embedding creation...\")\n",
    "#el=False\n",
    "prediction_deg, embedding_deg, true_label_deg=embedding_creation(x_deg, y_deg)\n",
    "\n",
    "print(\"saving the embeddings...\")\n",
    "\n",
    "save_embeddings(embedding_training, prediction_training, true_label_trainining, \"Conv_VGG-16_Stl_train.hdf5\" )\n",
    "save_embeddings(embedding_test, prediction_test, true_label_test, \"Conv_VGG-16_Stl_test.hdf5\" )\n",
    "save_embeddings(embedding_new, prediction_new, true_label_new, \"Conv_VGG-16_Stl_new.hdf5\" )\n",
    "save_embeddings(embedding_deg, prediction_deg, true_label_deg, \"Conv_VGG-16_Stl_deg.hdf5\" )\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}