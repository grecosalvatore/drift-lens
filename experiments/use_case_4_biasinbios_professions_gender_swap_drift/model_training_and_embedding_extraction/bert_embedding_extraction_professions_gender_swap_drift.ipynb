{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5ce77b14-7423-4809-8947-c9fa841199fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/students/s289159/.conda/envs/airbnb-XAI-env/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "from transformers import BertTokenizer,BertForSequenceClassification, BertConfig\n",
    "from transformers.pipelines import pipeline\n",
    "from datasets import load_dataset\n",
    "import datasets\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "from torch import nn\n",
    "import h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9ddbec06-2176-413a-aad9-bf9ad1f07412",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d55020a9-eebd-41d8-b411-6d773f67289d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = datasets.load_from_disk(\"bias_in_bios/opposite/data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f3339414-6478-44b2-994e-e1826090fc48",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['hard_text', 'all_profession_id', 'gender', 'all_profession_name', 'gender_name', 'profession_name', 'profession_id'],\n",
       "        num_rows: 39270\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['hard_text', 'all_profession_id', 'gender', 'all_profession_name', 'gender_name', 'profession_name', 'profession_id'],\n",
       "        num_rows: 15108\n",
       "    })\n",
       "    drift: Dataset({\n",
       "        features: ['hard_text', 'all_profession_id', 'gender', 'all_profession_name', 'gender_name', 'profession_name', 'profession_id'],\n",
       "        num_rows: 106242\n",
       "    })\n",
       "    new_unseen: Dataset({\n",
       "        features: ['hard_text', 'all_profession_id', 'gender', 'all_profession_name', 'gender_name', 'profession_name', 'profession_id'],\n",
       "        num_rows: 94184\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4b7dfcef-9b31-4675-8d98-2cb008804461",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_train = ds[\"train\"].to_pandas()\n",
    "df_test = ds[\"test\"].to_pandas()\n",
    "df_new_unseen = ds[\"new_unseen\"].to_pandas()\n",
    "df_drift = ds[\"drift\"].to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2757216d-4a40-40c8-b079-62728c112486",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_train.to_csv(\"bias_in_bios/opposite/data/df_train.csv\")\n",
    "df_test.to_csv(\"bias_in_bios/opposite/data/df_test.csv\")\n",
    "df_new_unseen.to_csv(\"bias_in_bios/opposite/data/df_new_unseen.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0af0c18f-7c25-423b-8ad7-c8d10ce39d8f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "df_drift.to_csv(\"bias_in_bios/opposite/data/df_drift.csv\", index=False, quoting=csv.QUOTE_ALL)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f0b8c66c-f607-477e-882a-b68b114c81bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTPUT_DIR = \"bias_in_bios/opposite/saved_model/best_model\"\n",
    "CONFIG_NAME = \"config.json\"\n",
    "WEIGHTS_NAME = \"pytorch_model.bin\"\n",
    "BERT_MODEL = 'bert-base-uncased' # BERT model type\n",
    "\n",
    "config = BertConfig.from_pretrained(os.path.join(OUTPUT_DIR, CONFIG_NAME), output_hidden_states=True)\n",
    "model = BertForSequenceClassification.from_pretrained(os.path.join(OUTPUT_DIR), config=config)\n",
    "model = model.to(device)\n",
    "tokenizer = BertTokenizer.from_pretrained(BERT_MODEL, do_lower_case=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c9c32969-72ad-4144-a55f-62b221c27995",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer_kwargs = {\"padding\":\"max_length\", \"truncation\":True}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "efc8f4e7-8abb-4ea3-95a0-888b6e4072ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "id2label = {0: \"professor\", 1: \"physician\", 2: \"attorney\", 3: \"photographer\", 4: \"journalist\", 5: \"nurse\"}\n",
    "\n",
    "label2id = {v: k for k, v in id2label.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "77561574-8253-4d50-82ce-172fd17a4f7d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['hard_text', 'all_profession_id', 'gender', 'all_profession_name', 'gender_name', 'profession_name', 'profession_id'],\n",
       "        num_rows: 39270\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['hard_text', 'all_profession_id', 'gender', 'all_profession_name', 'gender_name', 'profession_name', 'profession_id'],\n",
       "        num_rows: 15108\n",
       "    })\n",
       "    drift: Dataset({\n",
       "        features: ['hard_text', 'all_profession_id', 'gender', 'all_profession_name', 'gender_name', 'profession_name', 'profession_id'],\n",
       "        num_rows: 106242\n",
       "    })\n",
       "    new_unseen: Dataset({\n",
       "        features: ['hard_text', 'all_profession_id', 'gender', 'all_profession_name', 'gender_name', 'profession_name', 'profession_id'],\n",
       "        num_rows: 94184\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "aaf9d4f0-8683-4761-9411-a5f67eb0eea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "from tqdm import tqdm\n",
    "from datasets import Dataset\n",
    "\n",
    "def extract_embedding_and_predict(model, tokenizer, hf_dataset, text_column, label_column, layer_id):\n",
    "    \n",
    "    X = hf_dataset[text_column]  # List of input texts\n",
    "    Y_original = hf_dataset[label_column]  # List of original labels (GT)\n",
    "    Y_original_names = [id2label[l] for l in Y_original]  # List of original labels' names (GT)\n",
    "    E = np.empty((0, 768))  # Initialize empty array of embeddings\n",
    "    Y_predicted = []  # Initialize empty list of predicted labels (IDs)\n",
    "    Y_predicted_names = []  # Initialize empty list of predicted labels (Names)\n",
    "    \n",
    "    BATCH_SIZE = 256\n",
    "    n_batch = len(hf_dataset) // BATCH_SIZE\n",
    "    remainder = len(hf_dataset) % BATCH_SIZE\n",
    "    \n",
    "    for i in tqdm(range(n_batch)):\n",
    "        input_texts = X[i * BATCH_SIZE : (i + 1) * BATCH_SIZE]\n",
    "        \n",
    "        tokenized_texts = tokenizer(input_texts, padding=True, truncation=True, return_tensors=\"pt\")\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            outputs = model(**tokenized_texts.to(device))\n",
    "            \n",
    "        batch_probabilities = nn.functional.softmax(outputs[\"logits\"], dim=-1)\n",
    "        batch_labels = torch.argmax(batch_probabilities, dim=1).tolist()\n",
    "        batch_labels_name = [id2label[l] for l in batch_labels] \n",
    "\n",
    "        Y_predicted.extend(batch_labels)\n",
    "        Y_predicted_names.extend(batch_labels_name)\n",
    "\n",
    "        last_layer_hidden_states_arr = outputs[\"hidden_states\"][layer_id].detach().cpu().numpy()                   \n",
    "        embedding_CLS_arr = last_layer_hidden_states_arr[:, 0, :]  # [BATCH_SIZE, 0 = CLS, 768]\n",
    "        E = np.vstack([E, embedding_CLS_arr])\n",
    "            \n",
    "    if remainder > 0:\n",
    "        input_texts = X[-remainder:]\n",
    "\n",
    "        tokenized_texts = tokenizer(input_texts, padding=True, truncation=True, return_tensors=\"pt\")\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**tokenized_texts.to(device))\n",
    "\n",
    "        batch_probabilities = nn.functional.softmax(outputs[\"logits\"], dim=-1)\n",
    "        batch_labels = torch.argmax(batch_probabilities, dim=1).tolist()\n",
    "        batch_labels_name = [id2label[l] for l in batch_labels] \n",
    "\n",
    "        Y_predicted.extend(batch_labels)\n",
    "        Y_predicted_names.extend(batch_labels_name)\n",
    "\n",
    "        last_layer_hidden_states_arr = outputs[\"hidden_states\"][layer_id].detach().cpu().numpy()                   \n",
    "        embedding_CLS_arr = last_layer_hidden_states_arr[:, 0, :]  # [BATCH_SIZE, 0 = CLS, 768]\n",
    "        E = np.vstack([E, embedding_CLS_arr])\n",
    "\n",
    "    return X, E, Y_original, Y_original_names, Y_predicted, Y_predicted_names\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "68b19a52-9ac1-40b7-a44f-135ef91353b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_embedding(output_path, X, E, Y_original, Y_original_names, Y_predicted, Y_predicted_names):\n",
    "\n",
    "    fp = h5py.File(output_path, \"w\")\n",
    "\n",
    "    #fp.create_dataset(\"X\", data=X, compression=\"gzip\")\n",
    "    fp.create_dataset(\"E\", data=E, compression=\"gzip\")\n",
    "    fp.create_dataset(\"Y_original\", data=Y_original, compression=\"gzip\")\n",
    "    fp.create_dataset(\"Y_original_names\", data=Y_original_names, compression=\"gzip\")\n",
    "    fp.create_dataset(\"Y_predicted\", data=Y_predicted, compression=\"gzip\")\n",
    "    fp.create_dataset(\"Y_predicted_names\", data=Y_predicted_names, compression=\"gzip\")\n",
    "    fp.close()\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c6105adb-75b9-4ad5-b0cd-a6663e4876c5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "embedding_dir = os.path.join(\"bias_in_bios\", \"opposite\", \"saved_embedding\")\n",
    "\n",
    "layer_id = -1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "681ee3cd-df45-40dd-9897-495eef2e49a3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 59/59 [01:24<00:00,  1.43s/it]\n"
     ]
    }
   ],
   "source": [
    "X_test, E_test, Y_original_test, Y_original_names_test, Y_predicted_test, Y_predicted_names_test = extract_embedding_and_predict(model, tokenizer, ds[\"test\"], layer_id=layer_id, text_column=\"hard_text\", label_column=\"profession_id\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "84f60e11-6c32-4af1-901d-9da828f6600f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 153/153 [04:04<00:00,  1.60s/it]\n"
     ]
    }
   ],
   "source": [
    "X_train, E_train, Y_original_train, Y_original_names_train, Y_predicted_train, Y_predicted_names_train = extract_embedding_and_predict(model, tokenizer, ds[\"train\"], layer_id=layer_id, text_column=\"hard_text\", label_column=\"profession_id\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4cb9560c-f7ec-43e5-b78a-f4edb72cd136",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 415/415 [12:04<00:00,  1.75s/it]\n"
     ]
    }
   ],
   "source": [
    "X_drift, E_drift, Y_original_drift, Y_original_names_drift, Y_predicted_drift, Y_predicted_names_drift = extract_embedding_and_predict(model, tokenizer, ds[\"drift\"], layer_id=layer_id, text_column=\"hard_text\", label_column=\"profession_id\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b7df62e0-255e-4c5e-af16-847e2c1f4ddf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 367/367 [09:43<00:00,  1.59s/it]\n"
     ]
    }
   ],
   "source": [
    "X_new_unseen, E_new_unseen, Y_original_new_unseen, Y_original_names_new_unseen, Y_predicted_new_unseen, Y_predicted_names_new_unseen = extract_embedding_and_predict(model, tokenizer, ds[\"new_unseen\"], layer_id=layer_id, text_column=\"hard_text\", label_column=\"profession_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "701b1c63-cf2f-4b34-8fc4-017fe11a90a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_embedding(os.path.join(embedding_dir, \"train_embedding.hdf5\"), \n",
    "                X_train, \n",
    "                E_train, \n",
    "                Y_original_train, \n",
    "                Y_original_names_train, \n",
    "                Y_predicted_train, \n",
    "                Y_predicted_names_train)\n",
    "\n",
    "save_embedding(os.path.join(embedding_dir, \"test_embedding.hdf5\"), \n",
    "                X_test, \n",
    "                E_test, \n",
    "                Y_original_test, \n",
    "                Y_original_names_test, \n",
    "                Y_predicted_test, \n",
    "                Y_predicted_names_test)\n",
    "\n",
    "save_embedding(os.path.join(embedding_dir, \"drift_embedding.hdf5\"), \n",
    "                X_drift, \n",
    "                E_drift, \n",
    "                Y_original_drift, \n",
    "                Y_original_names_drift, \n",
    "                Y_predicted_drift, \n",
    "                Y_predicted_names_drift)\n",
    "\n",
    "save_embedding(os.path.join(embedding_dir, \"new_unseen_embedding.hdf5\"), \n",
    "                X_new_unseen, \n",
    "                E_new_unseen, \n",
    "                Y_original_new_unseen, \n",
    "                Y_original_names_new_unseen, \n",
    "                Y_predicted_new_unseen, \n",
    "                Y_predicted_names_new_unseen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "11d0900c-4589-4a10-8a07-ae08a8be619d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['professor', 'professor', 'professor']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_original_names_train[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "39157c46-3728-4223-87ce-a96612221846",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['professor', 'professor', 'professor']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_predicted_names_train[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7a774c00-1e89-46af-9e46-3f3b2beacd84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['attorney', 'professor', 'professor']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_original_names_drift[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9da0c8ff-a57a-4b85-b64f-e2a03a9177a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['nurse', 'nurse', 'nurse']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_predicted_names_drift[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9927406b-ca13-49e1-bbe3-8aa75d011878",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8ad112a7-9503-43a7-a7f2-98d0ab7b5f4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.91      0.95     55754\n",
      "           1       0.81      0.95      0.87     11695\n",
      "           2       0.90      0.95      0.92     11036\n",
      "           3       0.93      0.95      0.94      6540\n",
      "           4       0.35      0.90      0.50      1007\n",
      "           5       1.00      1.00      1.00      8152\n",
      "\n",
      "    accuracy                           0.93     94184\n",
      "   macro avg       0.83      0.94      0.86     94184\n",
      "weighted avg       0.94      0.93      0.93     94184\n",
      "\n"
     ]
    }
   ],
   "source": [
    "report = classification_report(Y_original_new_unseen, Y_predicted_new_unseen)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8f8b3385-fec1-45e6-8a62-4fa90633b8bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.01      0.02     53259\n",
      "           1       0.03      0.00      0.00     20240\n",
      "           2       0.77      0.02      0.03     12471\n",
      "           3       0.78      0.02      0.04      8666\n",
      "           4       0.70      0.03      0.05      9871\n",
      "           5       0.00      0.04      0.00      1735\n",
      "\n",
      "    accuracy                           0.01    106242\n",
      "   macro avg       0.49      0.02      0.02    106242\n",
      "weighted avg       0.56      0.01      0.02    106242\n",
      "\n"
     ]
    }
   ],
   "source": [
    "report = classification_report(Y_original_drift, Y_predicted_drift)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9c2356f6-3ebd-43a7-99cf-acd4852021fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'hard_text': ['Prior to law school, Brittni graduated magna cum laude from DePaul University in 2011 with her Bachelor’s Degree in Psychology and Spanish. In 2014, she earned her law degree from Chicago-Kent College of Law. While at Chicago-Kent, Brittni was awarded two CALI Excellence for the Future Awards in both Legal Writing and for her seminar article regarding President Obama’s executive action, Deferred Action for Childhood Arrivals.',\n",
       "  'Previously, Dr. Lilly was a Research Assistant Professor in the Department of Pediatrics in the School of Medicine, also at WVU, where she worked as the biostatistician of the Coronary Artery Risk Detection in Appalachian Communities (CARDIAC) project.',\n",
       "  'She received her Ph.D. in Economics from the University of California, Irvine in 2013. Her research focuses on monetary economics, search theory, and international economics, with a particular emphasis on the effects of monetary policy on payment systems and credit markets.',\n",
       "  \"She received her Ph.D. in Computer Science from the University of California, Davis in 2014 (Advisors: Prof. Karl Levitt and Sean Peisert ). She got her bachelor degree in Electrical and Electronic Engineering from the University of Hong Kong in 2010. Prior to joining UMBC in 2017, she was a Weinberg fellow in Computational Data Analytics Group, Oak Ridge National Laboratory from 2015 to 2017. She is a member of Center for Hybrid Multicore Productivity Research (CHMPR) and Cyber Defense Lab (CDL) at UMBC. Dr. Duan's research interests include security, blockchain, distributed systems, cyber physical systems (sensor network, critical infrastructure systems), and graph-based data analytics. She leads the Distributed Systems and Security Lab.\",\n",
       "  'She graduated in May 2008 from Corban College with a Bachelor of Science in English-Journalism. She currently works as the Office Administrator at her church. Shawnee has been working along side her husband in youth ministry for four and a half years.',\n",
       "  'In this capacity, Cara teaches courses in urban studies and nonprofit management. Cara earned her Ph.D. in Urban Affairs and Public Policy from the University of Delaware in 2011. Cara has presented and published in a variety of areas including media and democracy, community planning, the impact of charter schools, and homelessness. Cara is the former Executive Director of the Homeless Planning Council of Delaware. In her role as ED, she co-authored “Delaware’s Ten Year Plan to End Chronic and Reduce Long-Term Homelessness.”',\n",
       "  'She is the Program Director for the Pediatric Infectious Diseases (PID) training program at Dalhousie University. Her primary research focus is vaccine safety, specifically, the clinical management of patients who have experienced adverse events following immunization, the risk of adverse events in patients with underlying conditions and vaccine safety and effectiveness in immunocompromised patients.',\n",
       "  'She is currently working on a book manuscript that examines the curious relationship between reading hearts and reading books in early African-American literature. Her articles on Phillis Wheatley and pleasure have appeared in Common-Place and The Feminist Wire.',\n",
       "  'Her research interests include emergency & crisis management, disaster response, migrant resettlement & integration, refugee crisis, collaborative governance, organizational behavior, complex adaptive systems, accountability & responsibility, decision analysis, and social network analysis.',\n",
       "  'She is also a registered landscape architect and founder of CLEAR, an interdisciplinary design practice that focuses on urban landscapes in Rust Belt cities. Her work as designer is complemented by a body of writing including two books, Large Parks (Princeton Architectural Press, 2007) and Case: Downsview Park Toronto (Prestel and Harvard Design School, 2001), that focus on contemporary design approaches to public parks and the relationship between landscape and cities. Her third edited volume, Formerly Urban: Projecting Rust Belt Futures (Princeton Architectural Press) is due out in Fall 2012.'],\n",
       " 'all_profession_id': [2, 21, 21, 21, 11, 21, 21, 21, 21, 21],\n",
       " 'gender': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       " 'all_profession_name': ['attorney',\n",
       "  'professor',\n",
       "  'professor',\n",
       "  'professor',\n",
       "  'journalist',\n",
       "  'professor',\n",
       "  'professor',\n",
       "  'professor',\n",
       "  'professor',\n",
       "  'professor'],\n",
       " 'gender_name': ['female',\n",
       "  'female',\n",
       "  'female',\n",
       "  'female',\n",
       "  'female',\n",
       "  'female',\n",
       "  'female',\n",
       "  'female',\n",
       "  'female',\n",
       "  'female'],\n",
       " 'profession_name': ['attorney',\n",
       "  'professor',\n",
       "  'professor',\n",
       "  'professor',\n",
       "  'journalist',\n",
       "  'professor',\n",
       "  'professor',\n",
       "  'professor',\n",
       "  'professor',\n",
       "  'professor'],\n",
       " 'profession_id': [2, 0, 0, 0, 4, 0, 0, 0, 0, 0]}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds[\"drift\"][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "31394014-b40e-4738-b284-21a90600f8e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "106242\n"
     ]
    }
   ],
   "source": [
    "print(len(ds[\"drift\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f67b4fc7-0e0b-4849-8d54-9c708abcae73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(106242, 768)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "E_drift.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ca00de3c-fcf2-49d2-a4dc-b28734cf2a5f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "106242\n"
     ]
    }
   ],
   "source": [
    "print(len(df_drift))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3be5c3c1-6dfd-4618-840c-9f44edcf0073",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "airbnb-XAI-env",
   "language": "python",
   "name": "airbnb-xai-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
