{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ba458271",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Get the absolute path of the project root\n",
    "project_root = os.path.abspath(\"..\")  # Moves up one level\n",
    "\n",
    "# Add the project root to sys.path\n",
    "sys.path.append(project_root)\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "26c7951b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "28429870",
   "metadata": {},
   "outputs": [],
   "source": [
    "id2label = [\"World\", \"Sports\", \"Business\", \"Sci/Tech (DRIFT)\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f6b2515a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from driftlens.driftlens import DriftLens"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b3f84d6",
   "metadata": {},
   "source": [
    "# Load Embedding Vectors and Texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4eadb979",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_embedding(filepath, E_name=None, Y_original_name=None, Y_predicted_name=None):\n",
    "    if filepath is not None:\n",
    "        with h5py.File(filepath, \"r\") as hf:\n",
    "            if E_name is None:\n",
    "                E = hf[\"E\"][()]\n",
    "            else:\n",
    "                E = hf[E_name][()]\n",
    "            if Y_original_name is None:\n",
    "                Y_original = hf[\"Y_original\"][()]\n",
    "            else:\n",
    "                Y_original = hf[Y_original_name][()]\n",
    "            if Y_predicted_name is None:\n",
    "                Y_predicted = hf[\"Y_predicted\"][()]\n",
    "            else:\n",
    "                Y_predicted = hf[Y_predicted_name][()]\n",
    "    else:\n",
    "        raise Exception(\"Error in loading the embedding file. Please set the embedding paths in the configuration file.\")\n",
    "    return E, Y_original, Y_predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7b410664",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = \"../experiments/use_case_1_ag_news_science_drift/static/saved_embeddings/bert/\"\n",
    "\n",
    "E_train, Y_original_train, Y_predicted_train = load_embedding(os.path.join(base_path, \"train_embedding_0_1_2.hdf5\"))\n",
    "E_test, Y_original_test, Y_predicted_test = load_embedding(os.path.join(base_path, \"test_embedding_0_1_2.hdf5\"))\n",
    "E_new_unseen, Y_original_new_unseen, Y_predicted_new_unseen = load_embedding(os.path.join(base_path, \"new_unseen_embedding_0_1_2.hdf5\"))\n",
    "E_drift, Y_original_drift, Y_predicted_drift = load_embedding(os.path.join(base_path, \"drift_embedding_3.hdf5\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "49907594",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(\"../experiments/use_case_1_ag_news_science_drift/static/data/bert/df_train.csv\")\n",
    "df_test = pd.read_csv(\"../experiments/use_case_1_ag_news_science_drift/static/data/bert/df_test.csv\")\n",
    "df_new_unseen = pd.read_csv(\"../experiments/use_case_1_ag_news_science_drift/static/data/bert/df_new_unseen.csv\")\n",
    "df_drift = pd.read_csv(\"../experiments/use_case_1_ag_news_science_drift/static/data/bert/df_drifted.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "42b17f83",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train[\"original_label\"] = Y_original_train\n",
    "df_train[\"predicted_label\"] = Y_predicted_train\n",
    "df_train[\"drifted_label\"] = [0]*len(df_train)\n",
    "\n",
    "df_test[\"original_label\"] = Y_original_test\n",
    "df_test[\"predicted_label\"] = Y_original_test\n",
    "df_test[\"drifted_label\"] = [0]*len(df_test)\n",
    "\n",
    "df_new_unseen[\"original_label\"] = Y_original_new_unseen\n",
    "df_new_unseen[\"predicted_label\"] = Y_original_new_unseen\n",
    "df_new_unseen[\"drifted_label\"] = [0]*len(df_new_unseen)\n",
    "\n",
    "df_drift[\"original_label\"] = Y_original_drift\n",
    "df_drift[\"predicted_label\"] = Y_predicted_drift\n",
    "df_drift[\"drifted_label\"] = [1]*len(df_drift)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adc03175",
   "metadata": {},
   "source": [
    "# Reduce Embedding Dimensionality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "061a3610",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embdding dimensionality reduction with baseline PCA skipped\n"
     ]
    }
   ],
   "source": [
    "flag_reduce_with_baseline = False\n",
    "\n",
    "if flag_reduce_with_baseline:\n",
    "    print(\"Embdding dimensionality reduction with baseline PCA ...\")\n",
    "    dl = DriftLens()\n",
    "    \n",
    "    baseline = dl.estimate_baseline(E=E_train,\n",
    "                                Y=Y_predicted_train,\n",
    "                                label_list=range(len(id2label)-1),\n",
    "                                batch_n_pc=150,\n",
    "                                per_label_n_pc=50)\n",
    "\n",
    "    E_train_per_label_reduced = []\n",
    "\n",
    "    for E, Y_predicted in zip(E_train, Y_predicted_train):\n",
    "        pca_model = baseline.get_PCA_model_by_label(Y_predicted)\n",
    "\n",
    "        # Ensure E is a 2D array before PCA transformation\n",
    "        if E.ndim == 1:  # If E is a 1D vector\n",
    "            E = E.reshape(1, -1)  # Reshape to (1, num_features)\n",
    "\n",
    "        # Apply PCA transformation\n",
    "        E_pca = pca_model.transform(E)  # This should be (1, reduced_dim)\n",
    "\n",
    "        # Reshape E_pca to ensure final shape is (1, reduced_dim) without unnecessary dimensions\n",
    "        E_train_per_label_reduced.append(E_pca.squeeze())  \n",
    "\n",
    "    # Convert list to numpy array\n",
    "    E_train_per_label_reduced = np.array(E_train_per_label_reduced)\n",
    "\n",
    "    # Check the final shape of E_drift_reduced\n",
    "    print(E_train_per_label_reduced.shape)\n",
    "    \n",
    "    E_test_per_label_reduced = []\n",
    "\n",
    "    for E, Y_predicted in zip(E_test, Y_predicted_test):\n",
    "        pca_model = baseline.get_PCA_model_by_label(Y_predicted)\n",
    "\n",
    "        # Ensure E is a 2D array before PCA transformation\n",
    "        if E.ndim == 1:  # If E is a 1D vector\n",
    "            E = E.reshape(1, -1)  # Reshape to (1, num_features)\n",
    "\n",
    "        # Apply PCA transformation\n",
    "        E_pca = pca_model.transform(E)  # This should be (1, reduced_dim)\n",
    "\n",
    "        # Reshape E_pca to ensure final shape is (1, reduced_dim) without unnecessary dimensions\n",
    "        E_test_per_label_reduced.append(E_pca.squeeze())  \n",
    "\n",
    "    # Convert list to numpy array\n",
    "    E_test_per_label_reduced = np.array(E_test_per_label_reduced)\n",
    "\n",
    "    # Check the final shape of E_drift_reduced\n",
    "    print(E_test_per_label_reduced.shape)\n",
    "    \n",
    "    E_new_unseen_per_label_reduced = []\n",
    "\n",
    "    for E, Y_predicted in zip(E_new_unseen, Y_predicted_new_unseen):\n",
    "        pca_model = baseline.get_PCA_model_by_label(Y_predicted)\n",
    "\n",
    "        # Ensure E is a 2D array before PCA transformation\n",
    "        if E.ndim == 1:  # If E is a 1D vector\n",
    "            E = E.reshape(1, -1)  # Reshape to (1, num_features)\n",
    "\n",
    "        # Apply PCA transformation\n",
    "        E_pca = pca_model.transform(E)  # This should be (1, reduced_dim)\n",
    "\n",
    "        # Reshape E_pca to ensure final shape is (1, reduced_dim) without unnecessary dimensions\n",
    "        E_new_unseen_per_label_reduced.append(E_pca.squeeze())  \n",
    "\n",
    "    # Convert list to numpy array\n",
    "    E_new_unseen_per_label_reduced = np.array(E_new_unseen_per_label_reduced)\n",
    "\n",
    "    # Check the final shape of E_drift_reduced\n",
    "    print(E_new_unseen_per_label_reduced.shape)\n",
    "    \n",
    "    E_drift_per_label_reduced = []\n",
    "\n",
    "    for E, Y_predicted in zip(E_drift, Y_predicted_drift):\n",
    "        pca_model = baseline.get_PCA_model_by_label(Y_predicted)\n",
    "\n",
    "        # Ensure E is a 2D array before PCA transformation\n",
    "        if E.ndim == 1:  # If E is a 1D vector\n",
    "            E = E.reshape(1, -1)  # Reshape to (1, num_features)\n",
    "\n",
    "        # Apply PCA transformation\n",
    "        E_pca = pca_model.transform(E)  # This should be (1, reduced_dim)\n",
    "\n",
    "        # Reshape E_pca to ensure final shape is (1, reduced_dim) without unnecessary dimensions\n",
    "        E_drift_per_label_reduced.append(E_pca.squeeze())  \n",
    "\n",
    "    # Convert list to numpy array\n",
    "    E_drift_per_label_reduced = np.array(E_drift_per_label_reduced)\n",
    "\n",
    "    # Check the final shape of E_drift_reduced\n",
    "    print(E_drift_per_label_reduced.shape)\n",
    "\n",
    "    E_train_per_batch_reduced = baseline.get_batch_PCA_model().transform(E_train)\n",
    "    E_test_per_batch_reduced = baseline.get_batch_PCA_model().transform(E_test)\n",
    "    E_new_unseen_per_batch_reduced = baseline.get_batch_PCA_model().transform(E_new_unseen)\n",
    "    E_drift_per_batch_reduced = baseline.get_batch_PCA_model().transform(E_drift)\n",
    "\n",
    "else:\n",
    "    print(\"Embdding dimensionality reduction with baseline PCA skipped\")\n",
    "    E_train_per_label_reduced = E_train\n",
    "    E_train_per_batch_reduced = E_train\n",
    "\n",
    "    E_test_per_label_reduced = E_test\n",
    "    E_test_per_batch_reduced = E_test\n",
    "\n",
    "    E_new_unseen_per_label_reduced = E_new_unseen\n",
    "    E_new_unseen_per_batch_reduced = E_new_unseen\n",
    "\n",
    "    E_drift_per_label_reduced = E_drift\n",
    "    E_drift_per_batch_reduced = E_drift\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3cb9d4fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(59480, 768)\n",
      "(5700, 768)\n",
      "(30520, 768)\n",
      "(31900, 768)\n"
     ]
    }
   ],
   "source": [
    "print(E_train_per_label_reduced.shape)\n",
    "print(E_test_per_label_reduced.shape)\n",
    "print(E_new_unseen_per_label_reduced.shape)\n",
    "print(E_drift_per_label_reduced.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ae955fb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(59480, 768)\n",
      "(5700, 768)\n",
      "(30520, 768)\n",
      "(31900, 768)\n"
     ]
    }
   ],
   "source": [
    "print(E_train_per_batch_reduced.shape)\n",
    "print(E_test_per_batch_reduced.shape)\n",
    "print(E_new_unseen_per_batch_reduced.shape)\n",
    "print(E_drift_per_batch_reduced.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20ff933f",
   "metadata": {},
   "source": [
    "# Clustering Algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9d3d894d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.cluster import SpectralClustering, KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import silhouette_score\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.spatial.distance import cdist\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "def find_optimal_clusters_with_spectral(embeddings, max_clusters=10, reduce_dim=False, n_dim=2, affinity='nearest_neighbors', plot=False):\n",
    "    if reduce_dim:\n",
    "        pca = PCA(n_components=n_dim)\n",
    "        embeddings = pca.fit_transform(embeddings)\n",
    "    \n",
    "    silhouette_scores = []\n",
    "    \n",
    "    for k in range(2, max_clusters + 1):\n",
    "        clustering = SpectralClustering(n_clusters=k, affinity=affinity, random_state=42, assign_labels='kmeans')\n",
    "        labels = clustering.fit_predict(embeddings)\n",
    "        \n",
    "        if len(set(labels)) > 1:\n",
    "            silhouette_scores.append(silhouette_score(embeddings, labels))\n",
    "        else:\n",
    "            silhouette_scores.append(None)\n",
    "    \n",
    "    best_k = np.argmax([s for s in silhouette_scores if s is not None]) + 2\n",
    "    spectral_best = SpectralClustering(n_clusters=best_k, affinity=affinity, random_state=42, assign_labels='kmeans')\n",
    "    labels = spectral_best.fit_predict(embeddings)\n",
    "    \n",
    "    if plot:\n",
    "        plt.figure(figsize=(8, 6))\n",
    "        plt.plot(range(2, max_clusters + 1), silhouette_scores, marker='o', label='Silhouette Score')\n",
    "        plt.xlabel('Number of Clusters (k)')\n",
    "        plt.ylabel('Silhouette Score')\n",
    "        plt.title('Silhouette Score vs. Clusters (Spectral)')\n",
    "        plt.grid(True)\n",
    "        plt.show()\n",
    "    \n",
    "    return best_k, spectral_best, labels\n",
    "\n",
    "def find_optimal_clusters_with_kmeans(embeddings, max_clusters=10, reduce_dim=False, n_dim=2, max_iter=1000, plot=False):\n",
    "    if reduce_dim:\n",
    "        pca = PCA(n_components=n_dim)\n",
    "        embeddings = pca.fit_transform(embeddings)\n",
    "    \n",
    "    silhouette_scores = []\n",
    "    inertias = []\n",
    "    for k in range(1, max_clusters + 1):\n",
    "        kmeans = KMeans(n_clusters=k, max_iter=max_iter, n_init=10)\n",
    "        labels = kmeans.fit_predict(embeddings)\n",
    "        inertias.append(kmeans.inertia_)\n",
    "        \n",
    "        if k > 1:\n",
    "            silhouette_scores.append(silhouette_score(embeddings, labels))\n",
    "        else:\n",
    "            silhouette_scores.append(None)\n",
    "    \n",
    "    best_k = np.argmax([s for s in silhouette_scores if s is not None]) + 2\n",
    "    kmeans_best = KMeans(n_clusters=best_k, max_iter=max_iter, n_init=10)\n",
    "    labels = kmeans_best.fit_predict(embeddings)\n",
    "    \n",
    "    if plot:\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        plt.subplot(1, 2, 1)\n",
    "        plt.plot(range(2, max_clusters + 1), silhouette_scores[1:], marker='o', label='Silhouette Score')\n",
    "        plt.xlabel('Number of Clusters (k)')\n",
    "        plt.ylabel('Silhouette Score')\n",
    "        plt.title('Silhouette Score vs. Clusters')\n",
    "        plt.grid(True)\n",
    "\n",
    "        plt.subplot(1, 2, 2)\n",
    "        plt.plot(range(1, max_clusters + 1), inertias, marker='o', label='Inertia', color='orange')\n",
    "        plt.xlabel('Number of Clusters (k)')\n",
    "        plt.ylabel('Inertia')\n",
    "        plt.title('Inertia vs. Clusters')\n",
    "        plt.grid(True)\n",
    "        plt.show()\n",
    "    \n",
    "    return best_k, kmeans_best, labels\n",
    "\n",
    "def find_optimal_clusters_with_gmm(embeddings, max_clusters=10, reduce_dim=False, n_dim=2, plot=False):\n",
    "    if reduce_dim:\n",
    "        pca = PCA(n_components=n_dim)\n",
    "        embeddings = pca.fit_transform(embeddings)\n",
    "    \n",
    "    silhouette_scores = []\n",
    "    bic_scores = []\n",
    "    \n",
    "    for k in range(2, max_clusters + 1):\n",
    "        gmm = GaussianMixture(n_components=k, covariance_type='full', random_state=42)\n",
    "        labels = gmm.fit_predict(embeddings)\n",
    "        bic_scores.append(gmm.bic(embeddings))\n",
    "        \n",
    "        if len(set(labels)) > 1:\n",
    "            silhouette_scores.append(silhouette_score(embeddings, labels))\n",
    "        else:\n",
    "            silhouette_scores.append(None)\n",
    "    \n",
    "    best_k = np.argmax([s for s in silhouette_scores if s is not None]) + 2\n",
    "    gmm_best = GaussianMixture(n_components=best_k, covariance_type='full', random_state=42)\n",
    "    labels = gmm_best.fit_predict(embeddings)\n",
    "    \n",
    "    if plot:\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        plt.subplot(1, 2, 1)\n",
    "        plt.plot(range(2, max_clusters + 1), silhouette_scores, marker='o', label='Silhouette Score')\n",
    "        plt.xlabel('Number of Clusters (k)')\n",
    "        plt.ylabel('Silhouette Score')\n",
    "        plt.title('Silhouette Score vs. Clusters')\n",
    "        plt.grid(True)\n",
    "    \n",
    "        plt.subplot(1, 2, 2)\n",
    "        plt.plot(range(2, max_clusters + 1), bic_scores, marker='o', label='BIC', color='orange')\n",
    "        plt.xlabel('Number of Clusters (k)')\n",
    "        plt.ylabel('BIC Score')\n",
    "        plt.title('BIC Score vs. Clusters')\n",
    "        plt.grid(True)\n",
    "        plt.show()\n",
    "    \n",
    "    return best_k, gmm_best, labels\n",
    "\n",
    "\n",
    "\n",
    "def get_centroids_and_closest_samples_spectral(embeddings, labels, k=5, distance_metric=\"euclidean\"):\n",
    "    \"\"\"\n",
    "    Compute pseudo-centroids (mean points) and find k closest samples to each centroid.\n",
    "    \"\"\"\n",
    "    unique_labels = np.unique(labels)\n",
    "    centroids = np.array([embeddings[labels == cluster_id].mean(axis=0) for cluster_id in unique_labels])\n",
    "    \n",
    "    distances = cdist(embeddings, centroids, metric=distance_metric)\n",
    "    \n",
    "    closest_samples = {}\n",
    "    for i, cluster_id in enumerate(unique_labels):\n",
    "        cluster_samples = np.where(labels == cluster_id)[0]\n",
    "        cluster_distances = distances[cluster_samples, i]\n",
    "        closest_k_indices = cluster_samples[np.argsort(cluster_distances)[:k]]\n",
    "        closest_samples[cluster_id] = closest_k_indices.tolist()\n",
    "    \n",
    "    return centroids, closest_samples\n",
    "\n",
    "def get_centroids_and_closest_samples_kmeans(embeddings, kmeans, labels, k=5, distance_metric=\"euclidean\"):\n",
    "    \"\"\"\n",
    "    Find the centroids and the k closest samples to each centroid.\n",
    "    \n",
    "    Parameters:\n",
    "    - embeddings (numpy array): High-dimensional input embeddings (n_samples, n_features).\n",
    "    - kmeans (KMeans): Trained KMeans model.\n",
    "    - labels (numpy array): Cluster labels for the embeddings.\n",
    "    - k (int): Number of closest samples to return for each centroid.\n",
    "    \n",
    "    Returns:\n",
    "    - centroids (numpy array): Coordinates of the centroids (n_clusters, n_features).\n",
    "    - closest_samples (dict): Dictionary where keys are cluster IDs and values are lists of sample indices.\n",
    "    \"\"\"\n",
    "    # Extract centroids from the KMeans\n",
    "    centroids = kmeans.cluster_centers_  # Shape: (n_clusters, n_features)\n",
    "    \n",
    "    if distance_metric == \"euclidean\":\n",
    "        # Calculate distances between each embedding and each centroid\n",
    "        distances = cdist(embeddings, centroids, metric='euclidean')  # Shape: (n_samples, n_clusters)\n",
    "    else:\n",
    "        # Compute cosine distance\n",
    "        distances = cdist(embeddings, centroids, metric='cosine')\n",
    "\n",
    "    \n",
    "    # Find the k closest samples for each centroid\n",
    "    closest_samples = {}\n",
    "    for cluster_id in range(len(centroids)):\n",
    "        # Get indices of samples belonging to the current cluster\n",
    "        cluster_samples = np.where(labels == cluster_id)[0]\n",
    "        # Filter distances to only include samples in the current cluster\n",
    "        cluster_distances = distances[cluster_samples, cluster_id]\n",
    "        # Sort by distance and get the indices of the k smallest distances\n",
    "        closest_k_indices = cluster_samples[np.argsort(cluster_distances)[:k]]\n",
    "        closest_samples[cluster_id] = closest_k_indices.tolist()\n",
    "    \n",
    "    return centroids, closest_samples\n",
    "\n",
    "\n",
    "def get_centroids_and_closest_samples_gmm(embeddings, gmm, labels, k=5, distance_metric=\"cosine\"):\n",
    "    \"\"\"\n",
    "    Find the centroids and the k closest samples to each centroid for GMM clusters.\n",
    "    \"\"\"\n",
    "    centroids = gmm.means_\n",
    "    \n",
    "    distances = cdist(embeddings, centroids, metric=distance_metric)\n",
    "    \n",
    "    closest_samples = {}\n",
    "    for cluster_id in range(len(centroids)):\n",
    "        cluster_samples = np.where(labels == cluster_id)[0]\n",
    "        cluster_distances = distances[cluster_samples, cluster_id]\n",
    "        closest_k_indices = cluster_samples[np.argsort(cluster_distances)[:k]]\n",
    "        closest_samples[cluster_id] = closest_k_indices.tolist()\n",
    "    \n",
    "    return centroids, closest_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "10f35953",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_text_and_labels_from_ids(df, text_column, label_column, sample_ids):\n",
    "    \"\"\"\n",
    "    Retrieve the text and labels for the given sample indices, using .iloc for integer-based indexing.\n",
    "    \n",
    "    Parameters:\n",
    "    - df (pandas.DataFrame): The DataFrame containing the text data.\n",
    "    - text_column (str): Name of the column containing text.\n",
    "    - label_column (str): Name of the column containing labels.\n",
    "    - sample_ids (list): List of sample indices (integer positions).\n",
    "    \n",
    "    Returns:\n",
    "    - List of tuples: Each tuple contains (text, label) corresponding to the indices.\n",
    "    \"\"\"\n",
    "    return df.iloc[sample_ids][[text_column, label_column]].to_records(index=False).tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "72eb470a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.special import comb\n",
    "from collections import Counter\n",
    "from math import log2\n",
    "\n",
    "def compute_purity(cluster_labels, true_labels):\n",
    "    clusters = np.unique(cluster_labels)\n",
    "    total_correct = 0\n",
    "    \n",
    "    for cluster in clusters:\n",
    "        # Indices of samples in this cluster\n",
    "        indices = np.where(cluster_labels == cluster)[0]\n",
    "        # True labels for these samples\n",
    "        true_labels_in_cluster = true_labels[indices]\n",
    "        \n",
    "        # Count occurrences of each true label and select the most common\n",
    "        most_common_count = Counter(true_labels_in_cluster).most_common(1)[0][1]\n",
    "        total_correct += most_common_count\n",
    "    \n",
    "    purity = total_correct / len(true_labels)\n",
    "    return purity\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1b48fe8",
   "metadata": {},
   "source": [
    "# Drifted Window Prototypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ac36add3",
   "metadata": {},
   "outputs": [],
   "source": [
    "window_size = 2000\n",
    "drift_percetage = 20\n",
    "\n",
    "n_samples_drift = int((window_size*drift_percetage)/100)\n",
    "samples_per_class = int((window_size - n_samples_drift) // (len(id2label)-1))\n",
    "\n",
    "# Ensure there are enough samples in each group\n",
    "if df_new_unseen[\"original_label\"].value_counts().min() < samples_per_class:\n",
    "    raise ValueError(\"Not enough samples in one or more groups to split equally.\")\n",
    "\n",
    "# Initialize an empty list to store indices\n",
    "indices_new_unseen = []\n",
    "\n",
    "# Iterate through each unique value in the \"original_label\" column\n",
    "for label in df_new_unseen[\"original_label\"].unique():\n",
    "    # Get all indices for the current label\n",
    "    label_indices = df_new_unseen[df_new_unseen[\"original_label\"] == label].index\n",
    "    # Randomly sample the specified number of indices\n",
    "    sampled_indices = np.random.choice(label_indices, size=samples_per_class, replace=False)\n",
    "    # Add the sampled indices to the list\n",
    "    indices_new_unseen.extend(sampled_indices)\n",
    "\n",
    "# Convert to a numpy array if needed\n",
    "indices_new_unseen = np.array(indices_new_unseen)\n",
    "\n",
    "# Randomly sample indices for df_drift and E_drift\n",
    "indices_drift = np.random.choice(df_drift.index, size=n_samples_drift, replace=False)\n",
    "\n",
    "# Sample both the DataFrame and the corresponding NumPy array\n",
    "df_drifted_window_per_label = pd.concat([\n",
    "    df_new_unseen.loc[indices_new_unseen].copy(),\n",
    "    df_drift.loc[indices_drift].copy()\n",
    "], axis=0).copy()\n",
    "\n",
    "E_drifted_window_per_label = np.concatenate([\n",
    "    E_new_unseen_per_label_reduced[indices_new_unseen],\n",
    "    E_drift_per_label_reduced[indices_drift]\n",
    "]).copy()\n",
    "\n",
    "\n",
    "df_drifted_window_per_batch = pd.concat([\n",
    "    df_new_unseen.loc[indices_new_unseen].copy(),\n",
    "    df_drift.loc[indices_drift].copy()\n",
    "], axis=0).copy()\n",
    "\n",
    "E_drifted_window_per_batch = np.concatenate([\n",
    "    E_new_unseen_per_batch_reduced[indices_new_unseen],\n",
    "    E_drift_per_batch_reduced[indices_drift]\n",
    "]).copy()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb9521e8",
   "metadata": {},
   "source": [
    "## Per-label Explanations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "4510bf37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using kmeans with euclidean distance to identify prototypes\n"
     ]
    }
   ],
   "source": [
    "clustering_algorithms = [\"spectral\", \"kmeans\", \"gmm\"]\n",
    "clustering_algorithm_id = 1\n",
    "\n",
    "closest_samples_distance_metrics = [\"euclidean\", \"cosine\"]\n",
    "closest_samples_distance_metric_id = 0\n",
    "\n",
    "label_ids_to_explain = [0, 1, 2]\n",
    "\n",
    "max_clusters = 10\n",
    "\n",
    "k = 4  # Number of closest samples to find as prototypes\n",
    "\n",
    "flag_pca = False\n",
    "pca_dims = 75\n",
    "\n",
    "flag_normalize = False\n",
    "\n",
    "print(f\"Using {clustering_algorithms[clustering_algorithm_id]} with {closest_samples_distance_metrics[closest_samples_distance_metric_id]} distance to identify prototypes\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "5eea1c0e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Explainig Label: World\n",
      "0    533\n",
      "3     97\n",
      "Name: original_label, dtype: int64\n",
      "\n",
      "Using kmeans algorithm\n",
      "\n",
      "Cluster 0:\n",
      "\n",
      "  Text: Genetic Material May Help Make Nano-Devices: Study (Reuters) Reuters - The genetic building blocks that\\form the basis for life may also be used to build the tiny\\machines of nanotechnology, U.S. researchers said on Thursday., \n",
      " Label: Sci/Tech (DRIFT)\n",
      "\n",
      "\n",
      "  Text: UK expertise 'at risk from cuts' Gordon Brown's Whitehall cuts risk damaging the UK's ability to deal with key scientific problems, a trade union says., \n",
      " Label: Sci/Tech (DRIFT)\n",
      "\n",
      "\n",
      "  Text: News: DirecTV hacker sentenced to seven years A Canadian man arrested in the U.S. was allegedly responsible for putting 68,000 hacked smart cards on the street.\\, \n",
      " Label: Sci/Tech (DRIFT)\n",
      "\n",
      "\n",
      "  Text: Photo gallery: Bill Gates' home on Lake Washington Webshots users offer their photos of Bill Gates mansion in Medina, Wash., \n",
      " Label: Sci/Tech (DRIFT)\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Cluster 1:\n",
      "\n",
      "  Text: Britain Straw to Keep World Pressure on Sudan British Foreign Secretary Jack Straw flew to Sudan on Monday to keep up international pressure on Khartoum to comply with UN demands to end the conflict in Darfur that has already killed up to 50,000 people., \n",
      " Label: World\n",
      "\n",
      "\n",
      "  Text: Aid workers evacuated as violence flares in Darfur; at least 17 ... Fighting near a village in Sudan crisis-plagued Darfur region killed at least 17 people Monday, while helicopters rescued dozens of workers who fled into the bush to escape., \n",
      " Label: World\n",
      "\n",
      "\n",
      "  Text: Egypt calls for release of hostages in Iraq Egypt on Saturday called for the immediate release of Egyptians and other nationals taken hostage in violence-ravaged Iraq. quot;Egypt is against the practice of hostage-taking to , \n",
      " Label: World\n",
      "\n",
      "\n",
      "  Text: Israel To Benefit From Sinai Bombings: Experts A cohort of Egyptian security, political and diplomatic experts have concluded that Israel is the only party to benefit from the blasts , \n",
      " Label: World\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Explainig Label: Sports\n",
      "1    533\n",
      "3      4\n",
      "Name: original_label, dtype: int64\n",
      "\n",
      "Using kmeans algorithm\n",
      "\n",
      "Cluster 0:\n",
      "\n",
      "  Text: Clijsters Sidelined Until 2005 BRUSSELS (Reuters) - Kim Clijsters will be out of action for the rest of the season but does not need more surgery on her wrist after suffering an injury in the Belgian Open., \n",
      " Label: Sports\n",
      "\n",
      "\n",
      "  Text: Wild game in Oakland spoiled by altercation with fans Texas reliever Frank Francisco needed just one dangerous throw to overshadow an exciting back-and-forth game with a playoff atmosphere., \n",
      " Label: Sports\n",
      "\n",
      "\n",
      "  Text: Davis dismisses report Lee Suggs has been cleared to practice beginning Wednesday after missing the last two games with a neck injury. Coach Butch Davis said a report on ESPN speculating Suggs has stenosis, which is a narrowing of the spinal column, is untrue., \n",
      " Label: Sports\n",
      "\n",
      "\n",
      "  Text: Abdur-Rahim makes best of situation No, his position in the starting lineup isn solidified after one preseason game, and there a big question mark surrounding his future., \n",
      " Label: Sports\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Cluster 1:\n",
      "\n",
      "  Text: McCain Calls for Tougher Testing Policy Senator John McCain plans to introduce legislation requiring Major League Baseball players to be tested for steroids., \n",
      " Label: Sports\n",
      "\n",
      "\n",
      "  Text: Players' Fears Rising Baseball players and their families have become increasingly concerned about theft and kidnapping in Venezuela after the recent abduction of Ugueth Urbina's mother., \n",
      " Label: Sports\n",
      "\n",
      "\n",
      "  Text: TV stations admonished for broadcasting porn star allegations ... Romania broadcasting watchdog admonished three television stations Thursday for broadcasting a porn star claim that she had sex with Chelsea striker Adrian Mutu and that the player had used cocaine in the past., \n",
      " Label: Sports\n",
      "\n",
      "\n",
      "  Text: Trinidad set to punch back in Difficult questions. Questions about the futures of Felix Trinidad and Ricardo Mayorga. Very likely they will be questions only one of them will be able to answer., \n",
      " Label: Sports\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Explainig Label: Business\n",
      "2    533\n",
      "3    299\n",
      "Name: original_label, dtype: int64\n",
      "\n",
      "Using kmeans algorithm\n",
      "\n",
      "Cluster 0:\n",
      "\n",
      "  Text: Capital One Financial to Cut 750 Jobs Capital One Financial Corp., the holding company of Capital One Bank, plans to eliminate about 750 jobs as it shifts the majority of its production service operations to a U.S.-based supplier, the company reported Tuesday., \n",
      " Label: Business\n",
      "\n",
      "\n",
      "  Text: IBM to take \\$320M charge for pension settlement After settling a portion of a 5-year-old lawsuit involving its pension plan, Armonk, NY-based IBM Corp. (NYSE: IBM) will take a \\$320 million charge on its third-quarter earnings., \n",
      " Label: Business\n",
      "\n",
      "\n",
      "  Text: Gazprom Gets \\$10 Bln Loan, Plans Bond, Bankers Say (Update2) OAO Gazprom, the world biggest natural-gas company, will borrow \\$10 billion from six banks led by Deutsche Bank AG to help finance a bid for OAO Yukos Oil Co., \n",
      " Label: Business\n",
      "\n",
      "\n",
      "  Text: United Needs \\$2 Bln More in Cost Cuts CHICAGO (Reuters) - United Airlines, trying to revamp its business after nearly two years in bankruptcy, has told its unions it must terminate and replace their pensions as part of its drive to cut costs by an additional \\$2 billion a year., \n",
      " Label: Business\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Cluster 1:\n",
      "\n",
      "  Text: Merck info line swamped over Vioxx recall Hundreds of patients and physicians have contacted a special information line set up by Merck-Israel in the last few days after the international pharmaceutical company voluntarily withdrew Vioxx - one of the world most popular arthritis and acute , \n",
      " Label: Business\n",
      "\n",
      "\n",
      "  Text: DoCoMo and Motorola talk phones Japanese mobile phone company DoCoMo is in talks to buy 3G handsets from Motorola, the world's second largest handset maker., \n",
      " Label: Business\n",
      "\n",
      "\n",
      "  Text: IBM preps new top-end Unix servers Big Blue plans to announce the servers Friday, sources say, stirring up major new challenges for Sun and HP., \n",
      " Label: Sci/Tech (DRIFT)\n",
      "\n",
      "\n",
      "  Text: Are Cheaper Flat-Panel TVs On The Way? IFire aims to displace LCD TVs with its lower-cost display technology., \n",
      " Label: Sci/Tech (DRIFT)\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for label_id_to_explain in label_ids_to_explain:\n",
    "    print(f\"Explainig Label: {id2label[label_id_to_explain]}\")\n",
    "    \n",
    "    indices_current_label = np.where(df_drifted_window_per_label.predicted_label.values == label_id_to_explain)[0]\n",
    "\n",
    "    # Filter the DataFrame using the positional indices\n",
    "    df_current_label = df_drifted_window_per_label.iloc[indices_current_label].copy()\n",
    "\n",
    "    # Filter the NumPy array using the same positional indices\n",
    "    E_current_label = E_drifted_window_per_label[indices_current_label]\n",
    "    \n",
    "    if flag_pca:\n",
    "        pca = PCA(n_components=pca_dims)\n",
    "        E_current_label = pca.fit_transform(E_current_label)\n",
    "        \n",
    "    if flag_normalize:\n",
    "        E_current_label = normalize(E_current_label, norm='l2')\n",
    "    \n",
    "    print(df_current_label.original_label.value_counts())\n",
    "\n",
    "    \n",
    "    if clustering_algorithms[clustering_algorithm_id] == \"spectral\":\n",
    "        print(\"\\nUsing spectral algorithm\")\n",
    "        best_k, gmm_best, labels = find_optimal_clusters_with_spectral(E_current_label, max_clusters=max_clusters, reduce_dim=False)\n",
    "\n",
    "        centroids, closest_samples = get_centroids_and_closest_samples_spectral(E_current_label, labels, k=k, distance_metric=closest_samples_distance_metrics[closest_samples_distance_metric_id])\n",
    "            \n",
    "        \n",
    "        \n",
    "    elif clustering_algorithms[clustering_algorithm_id] == \"kmeans\":\n",
    "        print(\"\\nUsing kmeans algorithm\")\n",
    "        best_k, gmm_best, labels = find_optimal_clusters_with_kmeans(E_current_label, max_clusters=max_clusters, reduce_dim=False)\n",
    "\n",
    "        centroids, closest_samples = get_centroids_and_closest_samples_kmeans(E_current_label, gmm_best, labels, k=k, distance_metric=closest_samples_distance_metrics[closest_samples_distance_metric_id])\n",
    "        \n",
    "    elif clustering_algorithms[clustering_algorithm_id] == \"gmm\":\n",
    "        print(\"\\nUsing gmm algorithm\")\n",
    "        best_k, gmm_best, labels = find_optimal_clusters_with_gmm(E_current_label, max_clusters=max_clusters, reduce_dim=False)\n",
    "\n",
    "        centroids, closest_samples = get_centroids_and_closest_samples_gmm(E_current_label, gmm_best, labels, k=k, distance_metric=closest_samples_distance_metrics[closest_samples_distance_metric_id])\n",
    "    else:\n",
    "        print(\"\\nunknown clustering algorithm\")\n",
    "        break\n",
    "        \n",
    "        \n",
    "    # Extract text and labels for each cluster\n",
    "    cluster_texts_and_labels = {}\n",
    "\n",
    "    for cluster_id, sample_ids in closest_samples.items():\n",
    "        # Get text and labels for the current cluster\n",
    "        text_and_labels = get_text_and_labels_from_ids(df_current_label, 'text', 'original_label', sample_ids)\n",
    "        cluster_texts_and_labels[cluster_id] = text_and_labels\n",
    "\n",
    "    # Output results for each cluster\n",
    "    for cluster_id, texts_and_labels in cluster_texts_and_labels.items():\n",
    "        print(f\"\\nCluster {cluster_id}:\\n\")\n",
    "        for text, label in texts_and_labels:\n",
    "            print(f\"  Text: {text}, \\n Label: {id2label[label]}\")\n",
    "            print(\"\\n\")\n",
    "        print(\"\\n\")\n",
    "        print(\"\\n\")\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "648ad521",
   "metadata": {},
   "source": [
    "## Per-label Purity "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "25275178",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def run_purity_experiment(window_sizes, drift_percentages, labels_to_explain, E_new_unseen, E_drift, df_new_unseen, df_drift,\n",
    "                          n_iterations=100, max_clusters=10, flag_pca=False, pca_dims=150, k=4, flag_normalize=True, clustering_algorithm=\"kmeans\"):\n",
    "    results = []\n",
    "    \n",
    "    for window_size in window_sizes:\n",
    "        for drift_percentage in drift_percentages:\n",
    "            n_samples_drift = int((window_size * drift_percentage) / 100)\n",
    "            purity_scores = []\n",
    "            \n",
    "            for iteration in tqdm(range(n_iterations), desc=f\"WinSize {window_size}, Drift {drift_percentage}%\"):\n",
    "                samples_per_class = int((window_size - n_samples_drift) // df_new_unseen[\"original_label\"].nunique())\n",
    "                \n",
    "                if df_new_unseen[\"original_label\"].value_counts().min() < samples_per_class:\n",
    "                    raise ValueError(\"Not enough samples in one or more groups to split equally.\")\n",
    "                \n",
    "                indices_new_unseen = []\n",
    "                for label in df_new_unseen[\"original_label\"].unique():\n",
    "                    label_indices = df_new_unseen[df_new_unseen[\"original_label\"] == label].index\n",
    "                    sampled_indices = np.random.choice(label_indices, size=samples_per_class, replace=False)\n",
    "                    indices_new_unseen.extend(sampled_indices)\n",
    "                \n",
    "                indices_new_unseen = np.array(indices_new_unseen)\n",
    "                indices_drift = np.random.choice(df_drift.index, size=n_samples_drift, replace=False)\n",
    "                \n",
    "                df_new_unseen_drift = pd.concat([\n",
    "                    df_new_unseen.loc[indices_new_unseen].copy(),\n",
    "                    df_drift.loc[indices_drift].copy()\n",
    "                ], axis=0)\n",
    "                \n",
    "                E_new_unseen_drift = np.concatenate([\n",
    "                    E_new_unseen[indices_new_unseen],\n",
    "                    E_drift[indices_drift]\n",
    "                ])\n",
    "                \n",
    "                for label_id in labels_to_explain:\n",
    "                    indices_current_label = np.where(df_new_unseen_drift.predicted_label.values == label_id)[0]\n",
    "                    df_current_label = df_new_unseen_drift.iloc[indices_current_label].copy()\n",
    "                    E_current_label = E_new_unseen_drift[indices_current_label]\n",
    "                    \n",
    "                            \n",
    "                    if flag_normalize:\n",
    "                        E_current_label = normalize(E_current_label, norm='l2')\n",
    "                    \n",
    "                    if flag_pca:\n",
    "                        pca = PCA(n_components=pca_dims)\n",
    "                        E_current_label = pca.fit_transform(E_current_label)\n",
    "                    \n",
    "                    \n",
    "                    \n",
    "                    if clustering_algorithm == \"spectral\":\n",
    "                        best_k, gmm_best, labels = find_optimal_clusters_with_spectral(\n",
    "                            E_current_label, max_clusters=max_clusters, reduce_dim=False, n_dim=None\n",
    "                        )\n",
    "\n",
    "                    elif clustering_algorithm == \"kmeans\":\n",
    "                        best_k, gmm_best, labels = find_optimal_clusters_with_kmeans(\n",
    "                            E_current_label, max_clusters=max_clusters, reduce_dim=False, n_dim=None\n",
    "                        )\n",
    "\n",
    "                    elif clustering_algorithm == \"gmm\":\n",
    "                        best_k, gmm_best, labels = find_optimal_clusters_with_gmm(\n",
    "                            E_current_label, max_clusters=max_clusters, reduce_dim=False, n_dim=None\n",
    "                        )\n",
    "                    else:\n",
    "                        print(\"\\nunknown clustering algorithm\")\n",
    "                        break\n",
    "                    \n",
    "                    \n",
    "                    #print(labels)\n",
    "                    #print()\n",
    "                    #print(df_current_label.drifted_label.values)\n",
    "                    \n",
    "                    purity_score = compute_purity(labels, df_current_label.drifted_label.values)\n",
    "                    purity_scores.append(purity_score)\n",
    "            \n",
    "            mean_purity = np.mean(purity_scores)\n",
    "            std_purity = np.std(purity_scores)\n",
    "            results.append((window_size, drift_percentage, mean_purity, std_purity))\n",
    "            \n",
    "            print(f\"Purity for Window Size {window_size}, Drift {drift_percentage}%: {mean_purity:.4f} ± {std_purity:.4f}\")\n",
    "    \n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "aac61b50",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WinSize 1000, Drift 10%: 100%|██████████| 100/100 [00:50<00:00,  1.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Purity for Window Size 1000, Drift 10%: 0.9215 ± 0.0125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WinSize 1000, Drift 15%: 100%|██████████| 100/100 [00:48<00:00,  2.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Purity for Window Size 1000, Drift 15%: 0.8827 ± 0.0143\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WinSize 1000, Drift 20%: 100%|██████████| 100/100 [00:49<00:00,  2.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Purity for Window Size 1000, Drift 20%: 0.8525 ± 0.0203\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WinSize 2000, Drift 10%: 100%|██████████| 100/100 [01:29<00:00,  1.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Purity for Window Size 2000, Drift 10%: 0.9205 ± 0.0100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WinSize 2000, Drift 15%: 100%|██████████| 100/100 [01:35<00:00,  1.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Purity for Window Size 2000, Drift 15%: 0.8808 ± 0.0102\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WinSize 2000, Drift 20%: 100%|██████████| 100/100 [01:33<00:00,  1.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Purity for Window Size 2000, Drift 20%: 0.8448 ± 0.0137\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WinSize 4000, Drift 10%: 100%|██████████| 100/100 [04:40<00:00,  2.81s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Purity for Window Size 4000, Drift 10%: 0.9210 ± 0.0061\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WinSize 4000, Drift 15%: 100%|██████████| 100/100 [04:33<00:00,  2.73s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Purity for Window Size 4000, Drift 15%: 0.8805 ± 0.0069\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WinSize 4000, Drift 20%: 100%|██████████| 100/100 [04:30<00:00,  2.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Purity for Window Size 4000, Drift 20%: 0.8442 ± 0.0096\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Example usage:\n",
    "window_sizes = [1000, 2000, 4000]\n",
    "drift_percentages = [10, 15, 20]\n",
    "labels_to_explain = [0] # Purity for label world\n",
    "\n",
    "flag_pca = False\n",
    "pca_dims = 150\n",
    "\n",
    "flag_normalize = False\n",
    "\n",
    "clustering_algorithm = \"kmeans\"\n",
    "\n",
    "purity_results = run_purity_experiment(window_sizes, drift_percentages, labels_to_explain, \n",
    "                                       E_new_unseen_per_label_reduced, E_drift_per_label_reduced, df_new_unseen, df_drift,\n",
    "                                       clustering_algorithm=clustering_algorithm, flag_pca=flag_pca, pca_dims=pca_dims, flag_normalize=flag_normalize)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd88d609",
   "metadata": {},
   "source": [
    "## Per-batch Explanations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "4f6c24f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using kmeans with euclidean distance to identify prototypes\n"
     ]
    }
   ],
   "source": [
    "clustering_algorithms = [\"spectral\", \"kmeans\", \"gmm\"]\n",
    "clustering_algorithm_id = 1\n",
    "\n",
    "closest_samples_distance_metrics = [\"euclidean\", \"cosine\"]\n",
    "closest_samples_distance_metric_id = 0\n",
    "\n",
    "max_clusters = 10\n",
    "\n",
    "k = 4  # Number of closest samples to find as prototypes\n",
    "\n",
    "flag_pca = False\n",
    "pca_dims = 75\n",
    "\n",
    "flag_normalize = False\n",
    "\n",
    "print(f\"Using {clustering_algorithms[clustering_algorithm_id]} with {closest_samples_distance_metrics[closest_samples_distance_metric_id]} distance to identify prototypes\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "0a15b116",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2    533\n",
      "1    533\n",
      "0    533\n",
      "3    400\n",
      "Name: original_label, dtype: int64\n",
      "\n",
      "Using kmeans algorithm\n",
      "\n",
      "Cluster 0:\n",
      "\n",
      "  Text: Clijsters Sidelined Until 2005 BRUSSELS (Reuters) - Kim Clijsters will be out of action for the rest of the season but does not need more surgery on her wrist after suffering an injury in the Belgian Open., \n",
      " Label: Sports\n",
      "\n",
      "\n",
      "  Text: Wild game in Oakland spoiled by altercation with fans Texas reliever Frank Francisco needed just one dangerous throw to overshadow an exciting back-and-forth game with a playoff atmosphere., \n",
      " Label: Sports\n",
      "\n",
      "\n",
      "  Text: Davis dismisses report Lee Suggs has been cleared to practice beginning Wednesday after missing the last two games with a neck injury. Coach Butch Davis said a report on ESPN speculating Suggs has stenosis, which is a narrowing of the spinal column, is untrue., \n",
      " Label: Sports\n",
      "\n",
      "\n",
      "  Text: Heels savor 1st win over top 5 opponent North Carolina coach John Bunting never lost faith in his players, unabashedly supporting them even while their mistakes and poor play led to more losses., \n",
      " Label: Sports\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Cluster 1:\n",
      "\n",
      "  Text: Update 4: Alitalia Reportedly to Cut 5,000 Jobs Its future at stake, Italy flagship air carrier Alitalia said Monday it plans to cut 5,000 jobs - almost a fourth of its workforce - as part of restructuring efforts aimed at averting collapse., \n",
      " Label: Business\n",
      "\n",
      "\n",
      "  Text: IBM to take \\$320M charge for pension settlement After settling a portion of a 5-year-old lawsuit involving its pension plan, Armonk, NY-based IBM Corp. (NYSE: IBM) will take a \\$320 million charge on its third-quarter earnings., \n",
      " Label: Business\n",
      "\n",
      "\n",
      "  Text: Infineon Executives Guilty of DRAM Price-Fixing Four executives at German memory vendor Infineon Technologies AG and its US subsidiary have pled guilty to charges of illegally setting prices for PC memory chips, the US Department of Justice announced Thursday., \n",
      " Label: Sci/Tech (DRIFT)\n",
      "\n",
      "\n",
      "  Text: The Finer Points of Finance (The Motley Fool) The Motley Fool - NS: Most people know that Bankrate (Nasdaq: RATE - News) compiles rates for CDs, home equity loans, credit cards, mortgages, and other popular products. But some may not be aware that the company actually tracks data for over 310 product categories in over 400 markets (both numbers have expanded recently). Can you list a few of the more unusual products that you follow?, \n",
      " Label: Business\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Cluster 2:\n",
      "\n",
      "  Text: Aid workers evacuated as violence flares in Darfur; at least 17 ... Fighting near a village in Sudan crisis-plagued Darfur region killed at least 17 people Monday, while helicopters rescued dozens of workers who fled into the bush to escape., \n",
      " Label: World\n",
      "\n",
      "\n",
      "  Text: Britain Straw to Keep World Pressure on Sudan British Foreign Secretary Jack Straw flew to Sudan on Monday to keep up international pressure on Khartoum to comply with UN demands to end the conflict in Darfur that has already killed up to 50,000 people., \n",
      " Label: World\n",
      "\n",
      "\n",
      "  Text: Israel To Benefit From Sinai Bombings: Experts A cohort of Egyptian security, political and diplomatic experts have concluded that Israel is the only party to benefit from the blasts , \n",
      " Label: World\n",
      "\n",
      "\n",
      "  Text: Britain's Straw to Keep World Pressure on Sudan LONDON (Reuters) - British Foreign Secretary Jack Straw flew to Sudan on Monday to keep up international pressure on Khartoum to comply with U.N. demands to end the conflict in Darfur that has already killed up to 50,000 people., \n",
      " Label: World\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "if flag_normalize:\n",
    "    E_drifted_window_per_batch = normalize(E_drifted_window_per_batch, norm='l2')\n",
    "\n",
    "\n",
    "if flag_pca:\n",
    "    pca = PCA(n_components=pca_dims)\n",
    "    E_drifted_window_per_batch = pca.fit_transform(E_drifted_window_per_batch)\n",
    "    \n",
    "\n",
    "print(df_drifted_window_per_batch.original_label.value_counts())\n",
    "\n",
    "\n",
    "if clustering_algorithms[clustering_algorithm_id] == \"spectral\":\n",
    "    print(\"\\nUsing spectral algorithm\")\n",
    "    best_k, gmm_best, labels = find_optimal_clusters_with_spectral(E_drifted_window_per_batch, max_clusters=max_clusters, reduce_dim=False)\n",
    "\n",
    "    centroids, closest_samples = get_centroids_and_closest_samples_spectral(E_drifted_window_per_batch, labels, k=k, distance_metric=closest_samples_distance_metrics[closest_samples_distance_metric_id])\n",
    "\n",
    "elif clustering_algorithms[clustering_algorithm_id] == \"kmeans\":\n",
    "    print(\"\\nUsing kmeans algorithm\")\n",
    "    best_k, gmm_best, labels = find_optimal_clusters_with_kmeans(E_drifted_window_per_batch, max_clusters=max_clusters, reduce_dim=False)\n",
    "\n",
    "    centroids, closest_samples = get_centroids_and_closest_samples_kmeans(E_drifted_window_per_batch, gmm_best, labels, k=k, distance_metric=closest_samples_distance_metrics[closest_samples_distance_metric_id])\n",
    "\n",
    "elif clustering_algorithms[clustering_algorithm_id] == \"gmm\":\n",
    "    print(\"\\nUsing gmm algorithm\")\n",
    "    best_k, gmm_best, labels = find_optimal_clusters_with_gmm(E_drifted_window_per_batch, max_clusters=max_clusters, reduce_dim=False)\n",
    "\n",
    "    centroids, closest_samples = get_centroids_and_closest_samples_gmm(E_drifted_window_per_batch, gmm_best, labels, k=k, distance_metric=closest_samples_distance_metrics[closest_samples_distance_metric_id])\n",
    "else:\n",
    "    print(\"\\nunknown clustering algorithm\")\n",
    "\n",
    "\n",
    "\n",
    "# Extract text and labels for each cluster\n",
    "cluster_texts_and_labels = {}\n",
    "\n",
    "for cluster_id, sample_ids in closest_samples.items():\n",
    "    # Get text and labels for the current cluster\n",
    "    text_and_labels = get_text_and_labels_from_ids(df_drifted_window_per_batch, 'text', 'original_label', sample_ids)\n",
    "    cluster_texts_and_labels[cluster_id] = text_and_labels\n",
    "\n",
    "# Output results for each cluster\n",
    "for cluster_id, texts_and_labels in cluster_texts_and_labels.items():\n",
    "    print(f\"\\nCluster {cluster_id}:\\n\")\n",
    "    for text, label in texts_and_labels:\n",
    "        print(f\"  Text: {text}, \\n Label: {id2label[label]}\")\n",
    "        print(\"\\n\")\n",
    "    print(\"\\n\")\n",
    "    print(\"\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78a8254f",
   "metadata": {},
   "source": [
    "# Historical Prototypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56b98f4d",
   "metadata": {},
   "source": [
    "## Per-label Historical Explanations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "10b7a38d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using kmeans with euclidean distance to identify prototypes\n"
     ]
    }
   ],
   "source": [
    "clustering_algorithms = [\"spectral\", \"kmeans\", \"gmm\"]\n",
    "clustering_algorithm_id = 1\n",
    "\n",
    "closest_samples_distance_metrics = [\"euclidean\", \"cosine\"]\n",
    "closest_samples_distance_metric_id = 0\n",
    "\n",
    "label_ids_to_explain = [0, 1, 2]\n",
    "\n",
    "max_clusters = 10\n",
    "\n",
    "k = 4  # Number of closest samples to find as prototypes\n",
    "\n",
    "flag_pca = False\n",
    "pca_dims = 75\n",
    "\n",
    "flag_normalize = False\n",
    "\n",
    "print(f\"Using {clustering_algorithms[clustering_algorithm_id]} with {closest_samples_distance_metrics[closest_samples_distance_metric_id]} distance to identify prototypes\")\n",
    "\n",
    "df_historical = df_test\n",
    "E_historical = E_test_per_label_reduced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "f05f732b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Explainig Label: World\n",
      "0    1900\n",
      "Name: original_label, dtype: int64\n",
      "\n",
      "Using kmeans algorithm\n",
      "\n",
      "Cluster 0:\n",
      "\n",
      "  Text: Oil exports flow as strike woes ease A general strike in Nigeria, which has raised fears over oil supply from the world seventh-largest exporter, will likely end its first phase on Thursday quot;all going well quot;, union leaders said., \n",
      " Label: World\n",
      "\n",
      "\n",
      "  Text: Nigerian oil flows despite rebel threat-companies Oil should continue to flow from Nigeria, the world seventh largest exporter, despite a rebel threat to attack foreign oil workers in an quot;all-out war quot; due to start on Friday, multinational energy companies said., \n",
      " Label: World\n",
      "\n",
      "\n",
      "  Text: Tough Talks Ahead After EU Is Criticized Efforts to forge the world's largest free trade zone between the European Union and South America's Mercosur economic bloc are unlikely to be concluded by an Oct. 31 deadline, the EU said Thursday, with both sides declaring each other's trade offers insufficient., \n",
      " Label: World\n",
      "\n",
      "\n",
      "  Text: Oil Companies In Nigeria Say They Won Give In To Threats Major oil companies operating in Nigeria oil-rich southern region say they will not give in to threats of attacks on their facilities and employees by militias., \n",
      " Label: World\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Cluster 1:\n",
      "\n",
      "  Text: No progress in N.Korea, Japan talks on abductees : Talks between Japan and North Korea aimed at resolving a dispute over Japanese nationals abducted by the North decades ago ended Sunday without progress, Japanese officials said., \n",
      " Label: World\n",
      "\n",
      "\n",
      "  Text: Iraq PM to address US Congress Iraqi Prime Minister Iyad Allawi is to address a joint session of the US Congress as well as meeting President Bush., \n",
      " Label: World\n",
      "\n",
      "\n",
      "  Text: Final respects paid to Arafat Palestinians pay their last respects to Yasser Arafat after chaotic scenes at his burial in Ramallah., \n",
      " Label: World\n",
      "\n",
      "\n",
      "  Text: Straw: No British troops to Darfur British Foreign Minister Jack Straw said his country does not plan to deploy forces to Darfur in western Sudan but will provide technical assistance., \n",
      " Label: World\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Explainig Label: Sports\n",
      "1    1900\n",
      "Name: original_label, dtype: int64\n",
      "\n",
      "Using kmeans algorithm\n",
      "\n",
      "Cluster 0:\n",
      "\n",
      "  Text: Cougar Football Notes Houston, Texas- - Houston head football coach Art Briles finds himself in somewhat of a quandary as the Cougars prepared to play at the University of Southern Mississippi this Thursday night at MM Roberts Stadium in Hattiesburg, Miss., \n",
      " Label: Sports\n",
      "\n",
      "\n",
      "  Text: Beckham Practicing Again With Real Madrid David Beckham trained with Real Madrid on Monday for the first time since breaking two ribs last month during a World Cup qualifier., \n",
      " Label: Sports\n",
      "\n",
      "\n",
      "  Text: Jimenez ends Langer Match Play bid Spain Miguel Angel imenez completed a 2 amp;1 victory over German Bernhard Langer in their delayed World Match Play Championship quarter-final at Wentworth on Saturday., \n",
      " Label: Sports\n",
      "\n",
      "\n",
      "  Text: Gray, Demon Deacons Swing Back In Action, Seek To Shoot Down ... Justin Gray has had an ample amount of time to get his shooting stroke ready. Gray and No. 6 Wake Forest are back in action after an eight-day break when they visit Temple on Monday., \n",
      " Label: Sports\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Cluster 1:\n",
      "\n",
      "  Text: Japanese Baseball Players, Owners Reach Deal (Reuters) Reuters - Japanese baseball players and club\\representatives reached a deal Thursday to end the first strike\\in the 70-year history of the sport in Japan, with owners\\agreeing to let newcomers into the leagues as early as next\\season., \n",
      " Label: Sports\n",
      "\n",
      "\n",
      "  Text: Conte goes on TV and names names As the bassist for the pop-funk band Tower of Power, Victor Conte laid down a song backbone by playing a predetermined series of notes., \n",
      " Label: Sports\n",
      "\n",
      "\n",
      "  Text: Glory Comes Amid Empty Seats and Closed Shutters HERE in Old Europe, people install shutters outside their windows to keep out the heat, the pollution, the daylight, the noise. They also lock the shutters tight when they go away on holiday., \n",
      " Label: Sports\n",
      "\n",
      "\n",
      "  Text: Mets decline Leiter's \\$10.2 million option Al Leiter , 39, became a free agent when the New York Mets declined his \\$10.2 million option and decided to pay a \\$2.1 million buyout. The lefthander went 10-8 with a 3.21 ERA in 30 starts last season. He was on the disabled list from May 11 to June 1 because of tendinitis in his left shoulder . . ..., \n",
      " Label: Sports\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Explainig Label: Business\n",
      "2    1900\n",
      "Name: original_label, dtype: int64\n",
      "\n",
      "Using kmeans algorithm\n",
      "\n",
      "Cluster 0:\n",
      "\n",
      "  Text: Final edition for a respected Asian newsweekly HONG KONG The Far Eastern Economic Review, an often incisive newsweekly for more than half a century, will become a monthly opinion magazine in December, and virtually all of its employees will lose their jobs, Dow Jones announced on Thursday., \n",
      " Label: Business\n",
      "\n",
      "\n",
      "  Text: Aussies battle EU over cheese, champagne AP - The United States and Australia have prevailed in an interim ruling by World Trade Organisation (WTO) in a dispute over the protection given by the European Union to its regional goods such as Champagne wine and Feta cheese, trade officials said., \n",
      " Label: Business\n",
      "\n",
      "\n",
      "  Text: Cocoa Price Off, Ivory Coast Shot to Bits (Reuters) Reuters - World cocoa prices rose from intraday\\lows, but exports from the Ivory Coast, the key global\\supplier, remain on hold after mob violence and military\\clashes paralyze business in the West African country, traders\\said on Tuesday., \n",
      " Label: Business\n",
      "\n",
      "\n",
      "  Text: 5 of arthritis patients in Singapore take Bextra or Celebrex ... SINGAPORE : Doctors in the United States have warned that painkillers Bextra and Celebrex may be linked to major cardiovascular problems and should not be prescribed., \n",
      " Label: Business\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Cluster 1:\n",
      "\n",
      "  Text: Challenger disappoints with writedown The Kerry Packer-backed Challenger Financial Services Group has reported its first net loss since incorporating, impacted by a massive writedown of goodwill., \n",
      " Label: Business\n",
      "\n",
      "\n",
      "  Text: Freddie tightens controls Mortgage giant Freddie Mac announced Monday that it is shutting down some operations of its debt-securities sales division and transferring others - moves that experts said should tighten the company internal controls after an , \n",
      " Label: Business\n",
      "\n",
      "\n",
      "  Text: US delays WTO action over Airbus subsidy The US will offer an olive branch to Peter Mandelson, the European Union new trade commissioner, next week by delaying any escalation of the dispute over subsidies to Airbus and Boeing, a US trade official said on Thursday., \n",
      " Label: Business\n",
      "\n",
      "\n",
      "  Text: Colgate to cut workforce CONSUMER goods maker Colgate-Palmolive said today it would cut about 12 per cent of its 37,000-person work force and close a third of its factories worldwide as part of a four-year restructuring., \n",
      " Label: Business\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for label_id_to_explain in label_ids_to_explain:\n",
    "    print(f\"Explainig Label: {id2label[label_id_to_explain]}\")\n",
    "    \n",
    "    indices_current_label = np.where(df_historical.predicted_label.values == label_id_to_explain)[0]\n",
    "\n",
    "    # Filter the DataFrame using the positional indices\n",
    "    df_current_label = df_historical.iloc[indices_current_label].copy()\n",
    "\n",
    "    # Filter the NumPy array using the same positional indices\n",
    "    E_current_label = E_historical[indices_current_label]\n",
    "    \n",
    "    if flag_normalize:\n",
    "        E_current_label = normalize(E_current_label, norm='l2')\n",
    "    \n",
    "    \n",
    "    if flag_pca:\n",
    "        pca = PCA(n_components=pca_dims)\n",
    "        E_current_label = pca.fit_transform(E_current_label)\n",
    "    \n",
    "    print(df_current_label.original_label.value_counts())\n",
    "\n",
    "    \n",
    "    if clustering_algorithms[clustering_algorithm_id] == \"spectral\":\n",
    "        print(\"\\nUsing spectral algorithm\")\n",
    "        best_k, gmm_best, labels = find_optimal_clusters_with_spectral(E_current_label, max_clusters=max_clusters, reduce_dim=False)\n",
    "\n",
    "        centroids, closest_samples = get_centroids_and_closest_samples_spectral(E_current_label, labels, k=k, distance_metric=closest_samples_distance_metrics[closest_samples_distance_metric_id])\n",
    "            \n",
    "        \n",
    "        \n",
    "    elif clustering_algorithms[clustering_algorithm_id] == \"kmeans\":\n",
    "        print(\"\\nUsing kmeans algorithm\")\n",
    "        best_k, gmm_best, labels = find_optimal_clusters_with_kmeans(E_current_label, max_clusters=max_clusters, reduce_dim=False)\n",
    "\n",
    "        centroids, closest_samples = get_centroids_and_closest_samples_kmeans(E_current_label, gmm_best, labels, k=k, distance_metric=closest_samples_distance_metrics[closest_samples_distance_metric_id])\n",
    "        \n",
    "    elif clustering_algorithms[clustering_algorithm_id] == \"gmm\":\n",
    "        print(\"\\nUsing gmm algorithm\")\n",
    "        best_k, gmm_best, labels = find_optimal_clusters_with_gmm(E_current_label, max_clusters=max_clusters, reduce_dim=False)\n",
    "\n",
    "        centroids, closest_samples = get_centroids_and_closest_samples_gmm(E_current_label, gmm_best, labels, k=k, distance_metric=closest_samples_distance_metrics[closest_samples_distance_metric_id])\n",
    "    else:\n",
    "        print(\"\\nunknown clustering algorithm\")\n",
    "        break\n",
    "        \n",
    "        \n",
    "    # Extract text and labels for each cluster\n",
    "    cluster_texts_and_labels = {}\n",
    "\n",
    "    for cluster_id, sample_ids in closest_samples.items():\n",
    "        # Get text and labels for the current cluster\n",
    "        text_and_labels = get_text_and_labels_from_ids(df_current_label, 'text', 'original_label', sample_ids)\n",
    "        cluster_texts_and_labels[cluster_id] = text_and_labels\n",
    "\n",
    "    # Output results for each cluster\n",
    "    for cluster_id, texts_and_labels in cluster_texts_and_labels.items():\n",
    "        print(f\"\\nCluster {cluster_id}:\\n\")\n",
    "        for text, label in texts_and_labels:\n",
    "            print(f\"  Text: {text}, \\n Label: {id2label[label]}\")\n",
    "            print(\"\\n\")\n",
    "        print(\"\\n\")\n",
    "        print(\"\\n\")\n",
    "        print(\"\\n\")\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce1fae44",
   "metadata": {},
   "source": [
    "## Per-batch historical explanations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "d4c2852b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using kmeans with euclidean distance to identify prototypes\n"
     ]
    }
   ],
   "source": [
    "clustering_algorithms = [\"spectral\", \"kmeans\", \"gmm\"]\n",
    "clustering_algorithm_id = 1\n",
    "\n",
    "closest_samples_distance_metrics = [\"euclidean\", \"cosine\"]\n",
    "closest_samples_distance_metric_id = 0\n",
    "\n",
    "max_clusters = 10\n",
    "\n",
    "k = 4  # Number of closest samples to find as prototypes\n",
    "\n",
    "flag_pca = False\n",
    "pca_dims = 75\n",
    "\n",
    "flag_normalize = False\n",
    "\n",
    "print(f\"Using {clustering_algorithms[clustering_algorithm_id]} with {closest_samples_distance_metrics[closest_samples_distance_metric_id]} distance to identify prototypes\")\n",
    "\n",
    "\n",
    "df_historical_per_batch = df_test\n",
    "E_historical_per_batch = E_test_per_batch_reduced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "36fc300d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2    1900\n",
      "1    1900\n",
      "0    1900\n",
      "Name: original_label, dtype: int64\n",
      "\n",
      "Using kmeans algorithm\n",
      "\n",
      "Cluster 0:\n",
      "\n",
      "  Text: No progress in N.Korea, Japan talks on abductees : Talks between Japan and North Korea aimed at resolving a dispute over Japanese nationals abducted by the North decades ago ended Sunday without progress, Japanese officials said., \n",
      " Label: World\n",
      "\n",
      "\n",
      "  Text: Straw: No British troops to Darfur British Foreign Minister Jack Straw said his country does not plan to deploy forces to Darfur in western Sudan but will provide technical assistance., \n",
      " Label: World\n",
      "\n",
      "\n",
      "  Text: Libya hosts on Sudan Darfur conflict TRIPOLI, Libya: Libya confirmed that the leaders of Sudan, Egypt, Chad and Nigeria would join Moammar Gadhafi for a quot;mini-summit Sunday on Sudan Darfur region, which the United Nations calls the world worst humanitarian crisis., \n",
      " Label: World\n",
      "\n",
      "\n",
      "  Text: Final respects paid to Arafat Palestinians pay their last respects to Yasser Arafat after chaotic scenes at his burial in Ramallah., \n",
      " Label: World\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Cluster 1:\n",
      "\n",
      "  Text: Colgate to cut workforce CONSUMER goods maker Colgate-Palmolive said today it would cut about 12 per cent of its 37,000-person work force and close a third of its factories worldwide as part of a four-year restructuring., \n",
      " Label: Business\n",
      "\n",
      "\n",
      "  Text: US delays WTO action over Airbus subsidy The US will offer an olive branch to Peter Mandelson, the European Union new trade commissioner, next week by delaying any escalation of the dispute over subsidies to Airbus and Boeing, a US trade official said on Thursday., \n",
      " Label: Business\n",
      "\n",
      "\n",
      "  Text: EBay gets into rentals EBay plans to buy the apartment and home rental service Rent.com for \\$415 million, adding to its already exhaustive breadth of offerings., \n",
      " Label: Business\n",
      "\n",
      "\n",
      "  Text: Update 2: Alitalia, Unions Sign Deal Alitalia signed a deal with eight of nine unions Friday to split the loss-making Italian airline in two - part of the company plan to stave off bankruptcy., \n",
      " Label: Business\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Cluster 2:\n",
      "\n",
      "  Text: Cougar Football Notes Houston, Texas- - Houston head football coach Art Briles finds himself in somewhat of a quandary as the Cougars prepared to play at the University of Southern Mississippi this Thursday night at MM Roberts Stadium in Hattiesburg, Miss., \n",
      " Label: Sports\n",
      "\n",
      "\n",
      "  Text: Beckham Practicing Again With Real Madrid David Beckham trained with Real Madrid on Monday for the first time since breaking two ribs last month during a World Cup qualifier., \n",
      " Label: Sports\n",
      "\n",
      "\n",
      "  Text: Jimenez ends Langer Match Play bid Spain Miguel Angel imenez completed a 2 amp;1 victory over German Bernhard Langer in their delayed World Match Play Championship quarter-final at Wentworth on Saturday., \n",
      " Label: Sports\n",
      "\n",
      "\n",
      "  Text: Gray, Demon Deacons Swing Back In Action, Seek To Shoot Down ... Justin Gray has had an ample amount of time to get his shooting stroke ready. Gray and No. 6 Wake Forest are back in action after an eight-day break when they visit Temple on Monday., \n",
      " Label: Sports\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "if flag_normalize:\n",
    "    E_drifted_window_per_batch = normalize(E_drifted_window_per_batch, norm='l2')\n",
    "\n",
    "if flag_pca:\n",
    "    pca = PCA(n_components=pca_dims)\n",
    "    E_historical_per_batch = pca.fit_transform(E_historical_per_batch)\n",
    "\n",
    "print(df_historical_per_batch.original_label.value_counts())\n",
    "\n",
    "\n",
    "if clustering_algorithms[clustering_algorithm_id] == \"spectral\":\n",
    "    print(\"\\nUsing spectral algorithm\")\n",
    "    best_k, gmm_best, labels = find_optimal_clusters_with_spectral(E_historical_per_batch, max_clusters=max_clusters, reduce_dim=False)\n",
    "\n",
    "    centroids, closest_samples = get_centroids_and_closest_samples_spectral(E_historical_per_batch, labels, k=k, distance_metric=closest_samples_distance_metrics[closest_samples_distance_metric_id])\n",
    "\n",
    "elif clustering_algorithms[clustering_algorithm_id] == \"kmeans\":\n",
    "    print(\"\\nUsing kmeans algorithm\")\n",
    "    best_k, gmm_best, labels = find_optimal_clusters_with_kmeans(E_historical_per_batch, max_clusters=max_clusters, reduce_dim=False)\n",
    "\n",
    "    centroids, closest_samples = get_centroids_and_closest_samples_kmeans(E_historical_per_batch, gmm_best, labels, k=k, distance_metric=closest_samples_distance_metrics[closest_samples_distance_metric_id])\n",
    "\n",
    "elif clustering_algorithms[clustering_algorithm_id] == \"gmm\":\n",
    "    print(\"\\nUsing gmm algorithm\")\n",
    "    best_k, gmm_best, labels = find_optimal_clusters_with_gmm(E_historical_per_batch, max_clusters=max_clusters, reduce_dim=False)\n",
    "\n",
    "    centroids, closest_samples = get_centroids_and_closest_samples_gmm(E_historical_per_batch, gmm_best, labels, k=k, distance_metric=closest_samples_distance_metrics[closest_samples_distance_metric_id])\n",
    "else:\n",
    "    print(\"\\nunknown clustering algorithm\")\n",
    "\n",
    "\n",
    "\n",
    "# Extract text and labels for each cluster\n",
    "cluster_texts_and_labels = {}\n",
    "\n",
    "for cluster_id, sample_ids in closest_samples.items():\n",
    "    # Get text and labels for the current cluster\n",
    "    text_and_labels = get_text_and_labels_from_ids(df_historical_per_batch, 'text', 'original_label', sample_ids)\n",
    "    cluster_texts_and_labels[cluster_id] = text_and_labels\n",
    "\n",
    "# Output results for each cluster\n",
    "for cluster_id, texts_and_labels in cluster_texts_and_labels.items():\n",
    "    print(f\"\\nCluster {cluster_id}:\\n\")\n",
    "    for text, label in texts_and_labels:\n",
    "        print(f\"  Text: {text}, \\n Label: {id2label[label]}\")\n",
    "        print(\"\\n\")\n",
    "    print(\"\\n\")\n",
    "    print(\"\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "579657ac",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
